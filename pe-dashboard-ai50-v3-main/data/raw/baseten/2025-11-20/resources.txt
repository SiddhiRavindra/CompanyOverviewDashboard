Resources Resources Resources Resources from Baseten. ‌ All Webinar Guide Event ‌ Webinar Building on embedding models with Superhuman and Baseten ‌ Webinar Live podcast: What we learned building compound AI from our customers ‌ Webinar How to run DeepSeek-R1 in production ‌ Webinar How to build function calling and JSON mode for LLMs ‌ Webinar Why you need async inference in production ‌ Webinar How to run multi-model inference in production with Baseten Chains Guide High-performance embedding model inference Guide The complete DeepSeek model guide Guide The Baseten Inference Stack 1 2 3 ... 6 Baseten supports billions of custom, fine-tuned LLM calls per week from OpenEvidence, serving high-stakes medical information to healthcare providers in every major healthcare facility in the country. If you see a doctor today, chances are that they are leveraging OpenEvidence for trustworthy, up-to-date medical information at their fingertips. Baseten’s tireless dedication to reliability and deep support at scale has proven up to the task of supporting this at times literally life-or-death mission. Baseten has been extremely useful for our workflow. Its flexibility, especially with custom servers, lets us support complex analyst workloads throughout the day. The startup program has been a great help as we are building our application, and the Baseten team has consistently provided quick, helpful guidance whenever we hit setup challenges. Federico Puddu , Founder Baseten supports billions of custom, fine-tuned LLM calls per week from OpenEvidence, serving high-stakes medical information to healthcare providers in every major healthcare facility in the country. If you see a doctor today, chances are that they are leveraging OpenEvidence for trustworthy, up-to-date medical information at their fingertips. Baseten’s tireless dedication to reliability and deep support at scale has proven up to the task of supporting this at times literally life-or-death mission. Baseten has been extremely useful for our workflow. Its flexibility, especially with custom servers, lets us support complex analyst workloads throughout the day. The startup program has been a great help as we are building our application, and the Baseten team has consistently provided quick, helpful guidance whenever we hit setup challenges. Blog All posts Model performance BlogPost Kimi K2 Thinking at 140+ TPS on NVIDIA Blackwell Abu Qader 2 others AI engineering BlogPost Tool Calling in Inference Kenzie Amack 1 other News BlogPost Train AI Models When You Want. Deploy on Ultra Performant Infrastructure. Baseten Training Is GA. Raymond Cano 1 other Explore Baseten today Start deploying Talk to an engineer