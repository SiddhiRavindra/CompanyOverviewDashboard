{
  "company_name": "Baseten",
  "source_url": "https://www.baseten.com",
  "crawled_at": "2025-11-20T23:57:14Z",
  "http_status": 200,
  "title": "Inference Platform: Deploy AI models in production | Baseten",
  "canonical": "https://www.baseten.co/",
  "robots": "",
  "content_sha256": "e63e413fd7b28429491e1acd32c505ae7429229a8ea707b6e2a2212a9678c105",
  "content_length": 416173,
  "parser": "lxml",
  "structured_metadata": {
    "og_title": "Inference Platform: Deploy AI models in production | Baseten",
    "og_description": "Effortlessly serve optimized open source & custom models on the fastest, most reliable model delivery network.",
    "og_url": "https://www.baseten.co/",
    "og_site_name": "Baseten",
    "og_locale": "en_US",
    "og_image": "https://www.baseten.co/img/og-bg-2025.png",
    "og_type": "website",
    "twitter_card": "summary_large_image",
    "twitter_site": "@basetenco",
    "twitter_creator": "@basetenco",
    "twitter_title": "Inference Platform: Deploy AI models in production | Baseten",
    "twitter_description": "Effortlessly serve optimized open source & custom models on the fastest, most reliable model delivery network.",
    "twitter_image": "https://www.baseten.co/img/og-bg-2025.png",
    "description": "Effortlessly serve optimized open source & custom models on the fastest, most reliable model delivery network."
  },
  "version": 2
}