Cloud Pricing ‌ ‌ Pricing built for growth Production inference that won't break your product or your bank. Start building Talk to an engineer Trusted by top engineering and machine learning teams Basic Deploy custom, fine-tuned, and open-source models Included in Basic: Dedicated deployments Model APIs Fast cold starts SOC 2 Type II and HIPAA compliant Email and in-app chat support Deployment options Baseten $0 per month, pay as you go Get started Pro Unlimited autoscaling and priority compute access Everything in Basic plus: Priority access to high-demand GPUs Dedicated compute Higher Model API rate limits Hands-on engineering expertise Dedicated support on Slack and Zoom Deployment options Baseten Volume discounts available Get a quote Enterprise Full control in your cloud and ours Everything in Pro plus: Custom SLAs Training (Beta) Self-host deployments On-demand flex compute Use existing cloud commitments Full control over data residency Advanced security and compliance Custom global regions Deployment options Baseten Your VPC Hybrid Volume discounts available Get a quote Pricing Best-in-class model performance, effortless autoscaling, and blazing fast cold starts mean you get the most out of each GPU, saving money along the way. Model APIs Instant access to pre-optimized models running on the Baseten Inference Stack. Price per 1M tokens Model Input Output GLM 4.6 $0.60 $2.20 Try Model API Try Model API GPT OSS 120B $0.10 $0.50 Try Model API Try Model API Qwen3 Coder 480B $0.38 $1.53 Try Model API Try Model API Qwen3 235B 2507 $0.22 $0.80 Try Model API Try Model API Kimi K2 Thinking $0.60 $2.50 Try Model API Try Model API Kimi K2 Instruct $0.60 $2.50 Try Model API Try Model API DeepSeek V3.1 $0.50 $1.50 Try Model API Try Model API DeepSeek R1 0528 $2.55 $5.95 Try Model API Try Model API DeepSeek V3 0324 $0.77 $0.77 Try Model API Try Model API Dedicated Deployments Only pay for the compute you use, down to the minute. Price per Minute Hour GPU Instances Price T4 16 GiB VM, 4 vCPUs, 16 GiB RAM $0.01052 Deploy Deploy L4 24 GiB VRAM, 4 vCPUs, 16 GiB RAM $0.01414 Deploy Deploy A10G 24 GiB VM, 4 vCPUs, 16 GiB RAM $0.02012 Deploy Deploy A100 80 GiB VRAM, 12 vCPUs, 144 GiB RAM $0.06667 Deploy Deploy H100 MIG 40 GiB VRAM, 13 vCPUs, 117 GiB RAM $0.0625 Deploy Deploy H100 80 GiB VRAM, 26 vCPUs, 234 GiB RAM $0.10833 Deploy Deploy B200 180 GiB VRAM, 28 vCPUs, 384 GiB RAM $0.16633 Deploy Deploy CPU Instances Price 1x2 1 vCPU, 2 GiB RAM $0.00058 Deploy Deploy 1x4 1 vCPU, 4 GiB RAM $0.00086 Deploy Deploy 2x8 2 vCPUs, 8 GiB RAM $0.00173 Deploy Deploy 4x16 4 vCPUs, 16 GiB RAM $0.00346 Deploy Deploy 8x32 8 vCPUs, 32 GiB RAM $0.00691 Deploy Deploy 16x64 16 vCPUs, 64 GiB RAM $0.01382 Deploy Deploy Talk to Sales about compute in other countries and regions. Training Get 20% of Training spend back as credits for Dedicated Deployments. Price per Minute Hour GPU Instances Price T4 16 GiB VM, 4 vCPUs, 16 GiB RAM $0.01052 Request access Request access L4 24 GiB VRAM, 4 vCPUs, 16 GiB RAM $0.01414 Request access Request access A10G 24 GiB VM, 4 vCPUs, 16 GiB RAM $0.02012 Request access Request access A100 80 GiB VRAM, 12 vCPUs, 144 GiB RAM $0.06667 Request access Request access H100 MIG 40 GiB VRAM, 13 vCPUs, 117 GiB RAM $0.0625 Request access Request access H100 80 GiB VRAM, 26 vCPUs, 234 GiB RAM $0.10833 Request access Request access B200 180 GiB VRAM, 28 vCPUs, 384 GiB RAM $0.16633 Request access Request access Talk to Sales about compute in other countries and regions. Common questions Contact us Which models can I run on Baseten? You can deploy open source and custom models on Baseten. Start with an off-the-shelf model from our model library . Or deploy any model using Truss , our open source standard for packaging and serving models built in any framework. Which GPUs are available on Baseten? You have control over what GPUs your models use. See our instance type reference for a full list of the GPUs currently available on Baseten. Reach out to us to request additional GPU types. Do you offer free credits to get started? Yes, new Baseten accounts come with credits so you can get to know the UI and experiment with deployments for free. Is Baseten secure? Yes, Baseten is SOC 2 Type II certified and HIPAA compliant. You can read more about our SOC 2 Type II certification here . And you can read more about our HIPAA compliance here . Do I pay for idle time on Baseten? No, you do not pay for idle time – you only pay for the time your model is using compute on Baseten. This includes the time your model is actively deploying, scaling up or down, or making predictions. And you have full control over how your model scales up or down. What level of customer support do you offer? Customer support levels vary by plan. We offer email, in-app chat, Slack, and Zoom support. We also offer dedicated forward-deployed engineering support. Reach out to our team to figure out a customer support level that works for your needs. Do you offer discounts on compute? Yes, discounts on compute can be negotiated as part of our Pro and Enterprise plans. Reach out to our team to learn more. Can I deploy Baseten on my own infrastructure? Yes, you can self-host Baseten in order to manage security and use your own cloud commitments. Talk to our engineers to learn more. Explore Baseten today Start deploying Talk to an engineer