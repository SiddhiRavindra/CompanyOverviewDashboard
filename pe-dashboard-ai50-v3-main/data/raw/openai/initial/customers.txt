Safety & responsibility | OpenAI Skip to main content Log in Switch to ChatGPT (opens in a new window) Sora (opens in a new window) API Platform (opens in a new window) OpenAI Safety Safety at every step We believe in AI’s potential to make life better for everyone, which means making it safe for everyone Teach Test Share Safety doesn’t stop Building safe AI isn’t one and done. Every day is a chance to make things better. And every step helps anticipate, evaluate, and prevent risk. Teach Filter data OpenAI Policies Human values Test Red teaming System cards Preparedness evals Share Safety committees Alpha / Beta GA Feedback How we think about safety and alignment Learn more Leading the way in safety We collaborate with industry leaders and policymakers on the issues that matter most. Child safety Private information Deep fakes Bias Elections Conversations with OpenAI researchers Get inside OpenAI with our series that breaks down a range of topics around safety and more. Latest news on safety Introducing parental controls Product Sep 29, 2025 Our updated Preparedness Framework Publication Apr 15, 2025 An update on disrupting deceptive uses of AI Safety Oct 9, 2024 OpenAI safety practices Safety May 21, 2024 Go deeper on safety Explore the safety evaluations hub Sora 2 System Card Sora 2’s advanced capabilities require consideration of new potential risks, including nonconsensual use of likeness or misleading generations. To address these, we worked with internal red teamers to identify new challenges and inform corresponding mitigations. We’re taking an iterative approach to safety, focusing on areas where context is especially important or where risks are still emerging and are not fully understood. Learn more Addendum to GPT-5 system card: GPT-5-Codex This addendum outlines the comprehensive safety measures implemented for GPT‑5-Codex. It details both model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and product-level mitigations like agent sandboxing and configurable network access. Learn more GPT-5 System Card In this system card, we label the fast, high-throughput models as gpt-5-main and gpt-5-main-mini, and the thinking models as gpt-5-thinking and gpt-5-thinking-mini. In the API, we provide direct access to the thinking model, its mini version, and an even smaller and faster nano version of the thinking model, made for developers (gpt-5-thinking-nano). Learn more Addendum to OpenAI o3 and o4-mini system card: OpenAI o3 Operator This addendum to o3 and o4-mini system card describes the release of Operator, a Computer Using Agent capable of interacting with the web through its own browser. Operator is now powered by a o3-based model (instead of GPT-4o) with enhanced safety fine-tuning for computer use. Learn more Addendum to OpenAI o3 and o4-mini system card: Codex This addendum to o3 and o4-mini system card describes Codex, a cloud-based coding agent powered by codex-1, a fine-tuned version of OpenAI’s o3 model tailored specifically for software engineering tasks. Learn more OpenAI o3 and o4-mini System Card This is the first launch and system card to be released under Version 2 of our Preparedness Framework. OpenAI’s Safety Advisory Group (SAG) reviewed the results of our Preparedness evaluations and determined that OpenAI o3 and o4-mini do not reach the High threshold in any of our three Tracked Categories: Biological and Chemical Capability, Cybersecurity, and AI Self-improvement. Learn more Addendum to GPT-4o System Card: 4o image generation This addendum to the GPT‑4o system card describes the marginal risks we’ve focused on, and the work we have done to address them. Learn more GPT-4.5 System Card This system card outlines how we built and trained GPT‑4.5, evaluated its capabilities, and strengthened safety, following OpenAI’s safety process and Preparedness Framework. Learn more Deep research System Card This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas. Learn more OpenAI o3-mini System Card This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations. Learn more Operator System Card This report outlines the safety work carried out prior to releasing Operator including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas. Learn more Sora System Card This system card outlines the resulting mitigation stack, external red teaming efforts, evaluations, and ongoing research to refine these safeguards further. Learn more OpenAI o1 System Card This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework. Learn more GPT-4o System Card This system card takes a detailed look at speech-to-speech while also evaluating text and image capabilities. Learn more