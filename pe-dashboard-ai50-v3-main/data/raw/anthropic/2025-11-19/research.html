<!DOCTYPE html><html lang="en" class="__variable_bf5c26 __variable_afd42d __variable_5e9598 __variable_403256 __variable_57fc85 __variable_34e0db __variable_8bd1a6"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/42c6973fffeb4919-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/4e8887750eb14755-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/54e05bce7a25fe9c-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/5dd0369324c6e67e-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/73af0ef16113246e-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/7b13d0d32c6ab893-s.p.ttf" as="font" crossorigin="" type="font/ttf"/><link rel="preload" href="/_next/static/media/844eb89fa4effbb2-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/afcde17c90040887-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/c1cf232a330ed002-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/cfe503504e29ad5d-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/d7440d3c533a1aec-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/db2277a4dc542e54-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/5eee40f2a0b97eb9.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/fc59b9cd13857e1d.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/ef6165c716202714.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/8849da4b05334af0.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/30b381ed69092e80.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/43d206cc3630ea39.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/3ad8d51600dc7af0.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/18223d19411854a3.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/4a02c7e02d6928b7.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/7877fafacaca6dde.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/1878d521d08e94c9.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz" href="/_next/static/chunks/webpack-d3acc75c6151433c.js"/><script src="/_next/static/chunks/fd9d1056-0b3d1e0b010ff572.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/7023-f8015d96972cd1bb.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/main-app-55bbd77d79f9187f.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/8616-254847c413581317.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/app/(site)/layout-7ed9f87d12f7be91.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/d8e9270f-d57a4faa183a21b3.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/cc3e2e0e-9a8a205950288c5c.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/d8f92815-58bfe84c979b4d69.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/20e9ecfc-2a45032f86ca4c33.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/ccd63cfe-be58d908b1d80a17.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/3204862b-324c96543028037a.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/8ace8c09-2ef1471301516487.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/13b76428-b914bed72c3f2a72.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/2229-7e72d866a0a8a599.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/6648-415518a411696dac.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/775-e6da966f74201223.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/9105-9030fdd63d5e6625.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/3114-bea39ae2e9708c19.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/6156-9756cb2c325ff724.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/1148-941d0675ebb66cd3.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/app/(site)/research/%5Bslug%5D/page-843239828a5154b3.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><script src="/_next/static/chunks/app/(site)/not-found-e2aceb1bb7636934.js" async="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script><meta name="theme-color" content="#141413"/><title>Tracing the thoughts of a large language model \ Anthropic</title><meta name="description" content="Anthropic&#x27;s latest interpretability research: a new microscope to understand Claude&#x27;s internal mechanisms"/><meta name="msapplication-TileColor" content="141413"/><meta name="msapplication-config" content="/browserconfig.xml"/><meta property="og:title" content="Tracing the thoughts of a large language model"/><meta property="og:description" content="Anthropic&#x27;s latest interpretability research: a new microscope to understand Claude&#x27;s internal mechanisms"/><meta property="og:image" content="https://cdn.sanity.io/images/4zrzovbb/website/16c0eba69e06ee6e629756624d27117c3636d9ae-2400x1260.jpg"/><meta property="og:image:alt" content="A hand-drawn image where a black square overlaps with a white circle, revealing nodes and connections inside the circle, some of which are highlighted"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@AnthropicAI"/><meta name="twitter:creator" content="@AnthropicAI"/><meta name="twitter:title" content="Tracing the thoughts of a large language model"/><meta name="twitter:description" content="Anthropic&#x27;s latest interpretability research: a new microscope to understand Claude&#x27;s internal mechanisms"/><meta name="twitter:image" content="https://cdn.sanity.io/images/4zrzovbb/website/16c0eba69e06ee6e629756624d27117c3636d9ae-2400x1260.jpg"/><meta name="twitter:image:alt" content="A hand-drawn image where a black square overlaps with a white circle, revealing nodes and connections inside the circle, some of which are highlighted"/><link rel="shortcut icon" href="/favicon.ico"/><link rel="icon" href="/images/icons/favicon-32x32.png"/><link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png"/><link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png" sizes="180x180"/><link rel="mask-icon" href="/images/icons/safari-pinned-tab.svg" color="141413"/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule="" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz"></script></head><body><header class="SiteHeader_header__JZwqp" data-theme="light"><div class="SiteHeader_skipLinks__FBJM_"><a href="#main-content" class="SiteHeader_skipLink__5cD_c">Skip to main content</a><a href="#footer" class="SiteHeader_skipLink__5cD_c">Skip to footer</a></div><div class="page-wrapper SiteHeader_root__4Xd52"><a href="/" aria-label="Home"><div class="SiteHeader_logoDesktop__QF_jY"><div class="LogoWordmark_logo-lottie__HlhID"></div></div><svg class="Icon_icon__UdTNj SiteHeader_logoMobile__4zcw_" width="32" height="32" viewBox="0 0 46 32"><path d="M32.73 0h-6.945L38.45 32h6.945L32.73 0ZM12.665 0 0 32h7.082l2.59-6.72h13.25l2.59 6.72h7.082L19.929 0h-7.264Zm-.702 19.337 4.334-11.246 4.334 11.246h-8.668Z" fill="#000000"></path></svg></a><div class="SiteHeader_contentWrapper__UUrBN"><nav class="SiteHeader_nav__fFHf4"><ul class="SiteHeader_navList__TC1Q_"><li class="detail-m SiteHeader_navItem__iLoj9"><a href="/research" class="SiteHeader_navText__fhzDU">Research</a></li><li class="detail-m SiteHeader_navItem__iLoj9"><a href="/economic-futures" class="SiteHeader_navText__fhzDU">Economic Futures</a></li><li class="detail-m SiteHeader_navItem__iLoj9" data-category="Commitments"><button class="SiteHeader_navText__fhzDU" aria-haspopup="menu" aria-expanded="false" aria-controls="nav-dropdown-Commitments"><span>Commitments</span><svg class="Icon_icon__UdTNj SiteHeader_caretIcon__0UHHw" width="12" height="6.13" viewBox="0 0 8 5"><path d="M7.3016 0.231808C7.44932 0.0678162 7.70306 0.0546398 7.86724 0.20212C8.03137 0.349888 8.04461 0.603568 7.89692 0.767766L4.29684 4.76791L4.23434 4.82417C4.16662 4.87328 4.08425 4.89995 3.99918 4.89995C3.88588 4.89989 3.77733 4.85213 3.70152 4.76791L0.10144 0.767766L0.0537825 0.702139C-0.040206 0.541753 -0.0124254 0.331356 0.131128 0.20212C0.274775 0.0728844 0.486972 0.0674593 0.636608 0.1779L0.696765 0.231808L3.99918 3.90148L7.3016 0.231808Z" fill="currentColor"></path></svg></button></li><li class="detail-m SiteHeader_navItem__iLoj9" data-category="Learn"><button class="SiteHeader_navText__fhzDU" aria-haspopup="menu" aria-expanded="false" aria-controls="nav-dropdown-Learn"><span>Learn</span><svg class="Icon_icon__UdTNj SiteHeader_caretIcon__0UHHw" width="12" height="6.13" viewBox="0 0 8 5"><path d="M7.3016 0.231808C7.44932 0.0678162 7.70306 0.0546398 7.86724 0.20212C8.03137 0.349888 8.04461 0.603568 7.89692 0.767766L4.29684 4.76791L4.23434 4.82417C4.16662 4.87328 4.08425 4.89995 3.99918 4.89995C3.88588 4.89989 3.77733 4.85213 3.70152 4.76791L0.10144 0.767766L0.0537825 0.702139C-0.040206 0.541753 -0.0124254 0.331356 0.131128 0.20212C0.274775 0.0728844 0.486972 0.0674593 0.636608 0.1779L0.696765 0.231808L3.99918 3.90148L7.3016 0.231808Z" fill="currentColor"></path></svg></button></li><li class="detail-m SiteHeader_navItem__iLoj9"><a href="/news" class="SiteHeader_navText__fhzDU">News</a></li></ul></nav><div class="SiteHeader_claudeCtaWrapper__S0VLd"><a href="https://claude.ai/" class="SiteHeader_claudeCtaButton__ZmTxG detail-m" target="_blank" rel="noopener noreferrer">Try Claude</a><div class="SiteHeader_claudeCtaDropdownTrigger__7gtuH"><svg class="Icon_icon__UdTNj SiteHeader_claudeCtaIcon__VDITj" width="12" height="6.13" viewBox="0 0 8 5"><path d="M7.3016 0.231808C7.44932 0.0678162 7.70306 0.0546398 7.86724 0.20212C8.03137 0.349888 8.04461 0.603568 7.89692 0.767766L4.29684 4.76791L4.23434 4.82417C4.16662 4.87328 4.08425 4.89995 3.99918 4.89995C3.88588 4.89989 3.77733 4.85213 3.70152 4.76791L0.10144 0.767766L0.0537825 0.702139C-0.040206 0.541753 -0.0124254 0.331356 0.131128 0.20212C0.274775 0.0728844 0.486972 0.0674593 0.636608 0.1779L0.696765 0.231808L3.99918 3.90148L7.3016 0.231808Z" fill="currentColor"></path></svg></div></div><button class="SiteHeader_mobileIcon__OK1HE" aria-label="Navigation menu"><svg class="Icon_icon__UdTNj" width="24" height="24" viewBox="0 0 40 40"><path d="M18.75 28C19.1641 28.0002 19.5 28.3359 19.5 28.75C19.4999 29.1641 19.164 29.4998 18.75 29.5H7.91699C7.50281 29.5 7.16705 29.1642 7.16699 28.75C7.16699 28.3358 7.50278 28 7.91699 28H18.75ZM32.084 19.25C32.4979 19.2504 32.834 19.586 32.834 20C32.8339 20.4139 32.4979 20.7496 32.084 20.75H7.91699C7.50281 20.75 7.16705 20.4142 7.16699 20C7.16699 19.5858 7.50278 19.25 7.91699 19.25H32.084ZM32.084 10.5C32.4979 10.5004 32.834 10.836 32.834 11.25C32.8339 11.6639 32.4979 11.9996 32.084 12H7.91699C7.50282 12 7.16706 11.6642 7.16699 11.25C7.16699 10.8358 7.50278 10.5 7.91699 10.5H32.084Z" fill="#141413"></path></svg></button></div></div></header><main id="main-content" class=""><article><div class="page-wrapper PostDetail_wrapper__ea9fY"><div class="PostDetail_post-heading__LeDFA"><div class="PostDetail_post-detail-types-subjects__rYglE"><span class="PostDetail_post-subject__Kpz7U PostDetail_disabled__zFGBd PostDetail_chip__oT3gx detail-s">Interpretability</span></div><h1 class="h2">Tracing the thoughts of a large language model</h1><div class="PostDetail_post-timestamp__TBJ0Z text-label">Mar 27, 2025</div><div class="PostDetail_cta-button__4rDc7"><a href="https://transformer-circuits.pub/2025/attribution-graphs/biology.html" class="ButtonCta_button__miruF detail-m" rel="noopener" target="_blank" aria-label="Read the paper"><span>Read the paper</span></a></div></div><div class="text-b2 PostDetail_post-detail__6Ldh_"></div></div><div class="page-wrapper"><article><div class=""><div class="Body_body__XEXq7"><div class="Body_media-column__xPzhg"><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--></div><p class="Body_reading-column__t7kGM paragraph-m post-text">Language models like Claude aren&#x27;t programmed directly by humans—instead, they‘re trained<em> </em>on large amounts of data. During that training process, they learn their own strategies to solve problems. These strategies are encoded in the billions of computations a model performs for every word it writes. They arrive inscrutable to us, the model’s developers. This means that we don’t understand how models do most of the things they do.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">Knowing how models like Claude <em>think</em> would allow us to have a better understanding of their abilities, as well as help us ensure that they’re doing what we intend them to. For example:</p><ul class="Body_reading-column__t7kGM paragraph-m post-text"><li>Claude can speak dozens of languages. What language, if any, is it using &quot;in its head&quot;?</li><li>Claude writes text one word at a time. Is it only focusing on predicting the next word or does it ever plan ahead?</li><li>Claude can write out its reasoning step-by-step. Does this explanation represent the actual steps it took to get to an answer, or is it sometimes fabricating a plausible argument for a foregone conclusion?</li></ul><p class="Body_reading-column__t7kGM paragraph-m post-text">We take inspiration from the field of neuroscience, which has long studied the messy insides of thinking organisms, and try to build a kind of AI microscope that will let us identify patterns of activity and flows of information. There are limits to what you can learn just by talking to an AI model—after all, humans (even neuroscientists) don&#x27;t know all the details of how our own brains work. So we look inside.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">Today, we&#x27;re sharing two new papers that represent progress on the development of the &quot;microscope&quot;, and the application of it to see new &quot;AI biology&quot;. In <a href="https://transformer-circuits.pub/2025/attribution-graphs/methods.html">the first paper</a>, we extend <a href="https://www.anthropic.com/research/mapping-mind-language-model">our prior work</a> locating interpretable concepts (&quot;features&quot;) inside a model to link those concepts together into computational &quot;circuits&quot;, revealing parts of the pathway that transforms the words that go into Claude into the words that come out. In <a href="https://transformer-circuits.pub/2025/attribution-graphs/biology.html">the second</a>, we look inside Claude 3.5 Haiku, performing deep studies of simple tasks representative of ten crucial model behaviors, including the three described above. Our method sheds light on a part of what happens when Claude responds to these prompts, which is enough to see solid evidence that:</p><ul class="Body_reading-column__t7kGM paragraph-m post-text"><li>Claude sometimes thinks in a conceptual space that is shared between languages, suggesting it has a kind of universal “language of thought.” We show this by translating simple sentences into multiple languages and tracing the overlap in how Claude processes them.</li><li>Claude will plan what it will say many words ahead, and write to get to that destination. We show this in the realm of poetry, where it thinks of possible rhyming words in advance and writes the next line to get there. This is powerful evidence that even though models are trained to output one word at a time, they may think on much longer horizons to do so.</li><li>Claude, on occasion, will give a plausible-sounding argument designed to agree with the user rather than to follow logical steps. We show this by asking it for help on a hard math problem while giving it an incorrect hint. We are able to “catch it in the act” as it makes up its fake reasoning, providing a proof of concept that our tools can be useful for flagging concerning mechanisms in models.</li></ul><p class="Body_reading-column__t7kGM paragraph-m post-text">We were often surprised by what we saw in the model: In the poetry case study, we had set out to show that the model <em>didn&#x27;t</em> plan ahead, and found instead that it did. In a study of hallucinations, we found the counter-intuitive result that Claude&#x27;s default behavior is to decline to speculate when asked a question, and it only answers questions when something <em>inhibits</em> this default reluctance. In a response to an example jailbreak, we found that the model recognized it had been asked for dangerous information well before it was able to gracefully bring the conversation back around. While the problems we study can (<a href="https://arxiv.org/abs/2501.06346">and</a> <a href="https://arxiv.org/pdf/2406.12775">often</a> <a href="https://arxiv.org/abs/2406.00877">have</a> <a href="https://arxiv.org/abs/2307.13702">been</a>) analyzed with other methods, the general &quot;build a microscope&quot; approach lets us learn many things we wouldn&#x27;t have guessed going in, which will be increasingly important as models grow more sophisticated.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">These findings aren’t just scientifically interesting—they represent significant progress towards our goal of understanding AI systems and making sure they’re reliable. We also hope they prove useful to other groups, and potentially, in other domains: for example, interpretability techniques have found use in fields such as <a href="https://arxiv.org/abs/2410.03334">medical imaging</a> and <a href="https://www.goodfire.ai/blog/interpreting-evo-2">genomics</a>, as dissecting the internal mechanisms of models trained for scientific applications can reveal new insight about the science.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">At the same time, we recognize the limitations of our current approach. Even on short, simple prompts, our method only captures a fraction of the total computation performed by Claude, and the mechanisms we do see may have some artifacts based on our tools which don&#x27;t reflect what is going on in the underlying model. It currently takes a few hours of human effort to understand the circuits we see, even on prompts with only tens of words. To scale to the thousands of words supporting the complex thinking chains used by modern models, we will need to improve both the method and (perhaps with AI assistance) how we make sense of what we see with it.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">As AI systems are rapidly becoming more capable and are deployed in increasingly important contexts, Anthropic is investing in a portfolio of approaches including <a href="https://www.anthropic.com/research/constitutional-classifiers">realtime monitoring</a>, <a href="https://www.anthropic.com/research/claude-character">model character improvements</a>, and the <a href="https://www.anthropic.com/news/alignment-faking">science of alignment</a>. Interpretability research like this is one of the highest-risk, highest-reward investments, a significant scientific challenge with the potential to provide a unique tool for ensuring that AI is transparent. Transparency into the model’s mechanisms allows us to check whether it’s aligned with human values—and whether it’s worthy of our trust.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">For full details, please read <a href="https://transformer-circuits.pub/2025/attribution-graphs/methods.html">the</a> <a href="https://transformer-circuits.pub/2025/attribution-graphs/biology.html">papers</a>. Below, we invite you on a short tour of some of the most striking &quot;AI biology&quot; findings from our investigations.</p><h2 class="Body_reading-column__t7kGM display-sans-m post-heading" id="a-tour-of-ai-biology">A tour of AI biology</h2><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="how-is-claude-multilingual">How is Claude multilingual?</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">Claude speaks dozens of languages fluently—from English and French to Chinese and Tagalog. How does this multilingual ability work? Is there a separate &quot;French Claude&quot; and &quot;Chinese Claude&quot; running in parallel, responding to requests in their own language? Or is there some cross-lingual core inside?</p><div class="Body_media-column__xPzhg"><figure class="ImageWithCaption_e-imageWithCaption__8C2mY ImageWithCaption_inline-image__B15e_"><img loading="lazy" width="1650" height="750" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fe0e156ea6c912a385d66ed562187fced8c392a58-1650x750.png&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fe0e156ea6c912a385d66ed562187fced8c392a58-1650x750.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fe0e156ea6c912a385d66ed562187fced8c392a58-1650x750.png&amp;w=3840&amp;q=75"/><figcaption class="text-caption">Shared features exist across English, French, and Chinese, indicating a degree of conceptual universality.</figcaption></figure></div><p class="Body_reading-column__t7kGM paragraph-m post-text">Recent research on smaller models has shown hints of <a href="https://arxiv.org/abs/2410.06496">shared</a> <a href="https://arxiv.org/abs/2501.06346">grammatical</a> mechanisms across languages. We investigate this by asking Claude for the &quot;opposite of small&quot; across different languages, and find that the same core features for the concepts of smallness and oppositeness activate, and trigger a concept of largeness, which gets translated out into the language of the question. We find that the shared circuitry increases with model scale, with Claude 3.5 Haiku sharing more than twice the proportion of its features between languages as compared to a smaller model.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">This provides additional evidence for a kind of conceptual universality—a shared abstract space where meanings exist and where thinking can happen before being translated into specific languages. More practically, it suggests Claude can learn something in one language and apply that knowledge when speaking another. Studying how the model shares<em> </em>what it knows across contexts is important to understanding its most advanced reasoning capabilities, which generalize across many domains.</p><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="does-claude-plan-its-rhymes">Does Claude plan its rhymes?</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">How does Claude write rhyming poetry? Consider this ditty:</p><blockquote class="Body_reading-column__t7kGM paragraph-m post-text">He saw a carrot and had to grab it,<br/>His hunger was like a starving rabbit</blockquote><p class="Body_reading-column__t7kGM paragraph-m post-text">To write the second line, the model had to satisfy two constraints at the same time: the need to rhyme (with &quot;grab it&quot;), and the need to make sense (why did he grab the carrot?). Our guess was that Claude was writing word-by-word without much forethought until the end of the line, where it would make sure to pick a word that rhymes. We therefore expected to see a circuit with parallel paths, one for ensuring the final word made sense, and one for ensuring it rhymes.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">Instead, we found that Claude <em>plans ahead</em>. Before starting the second line, it began &quot;thinking&quot; of potential on-topic words that would rhyme with &quot;grab it&quot;. Then, with these plans in mind, it writes a line to end with the planned word.</p><div class="Body_media-column__xPzhg"><figure class="ImageWithCaption_e-imageWithCaption__8C2mY ImageWithCaption_inline-image__B15e_"><img loading="lazy" width="1650" height="900" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7032ed7db85b8cd3efe70a89deaf4f15bfe8fc05-1650x900.png&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7032ed7db85b8cd3efe70a89deaf4f15bfe8fc05-1650x900.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7032ed7db85b8cd3efe70a89deaf4f15bfe8fc05-1650x900.png&amp;w=3840&amp;q=75"/><figcaption class="text-caption">How Claude completes a two-line poem. Without any intervention (upper section), the model plans the rhyme &quot;rabbit&quot; at the end of the second line in advance. When we suppress the &quot;rabbit&quot; concept (middle section), the model instead uses a different planned rhyme. When we inject the concept &quot;green&quot; (lower section), the model makes plans for this entirely different ending.</figcaption></figure></div><p class="Body_reading-column__t7kGM paragraph-m post-text">To understand how this planning mechanism works in practice, we conducted an experiment inspired by how neuroscientists study brain function, by pinpointing and altering neural activity in specific parts of the brain (for example using electrical or magnetic currents). Here, we modified the part of Claude’s internal state that represented the &quot;rabbit&quot; concept. When we subtract out the &quot;rabbit&quot; part, and have Claude continue the line, it writes a new one ending in &quot;habit&quot;, another sensible completion. We can also inject the concept of &quot;green&quot; at that point, causing Claude to write a sensible (but no-longer rhyming) line which ends in &quot;green&quot;. This demonstrates both planning ability and adaptive flexibility—Claude can modify its approach when the intended outcome changes.</p><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="mental-math">Mental math</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">Claude wasn&#x27;t designed as a calculator—it was trained on text, not equipped with mathematical algorithms. Yet somehow, it can add numbers correctly &quot;in its head&quot;. How does a system trained to predict the next word in a sequence learn to calculate, say, 36+59, without writing out each step?</p><p class="Body_reading-column__t7kGM paragraph-m post-text">Maybe the answer is uninteresting: the model might have memorized massive addition tables and simply outputs the answer to any given sum because that answer is in its training data. Another possibility is that it follows the traditional longhand addition algorithms that we learn in school.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">Instead, we find that Claude employs multiple computational paths that work in parallel. One path computes a rough approximation of the answer and the other focuses on precisely determining the last digit of the sum. These paths interact and combine with one another to produce the final answer. Addition is a simple behavior, but understanding how it works at this level of detail, involving a mix of approximate and precise strategies, might teach us something about how Claude tackles more complex problems, too.</p><div class="Body_media-column__xPzhg"><figure class="ImageWithCaption_e-imageWithCaption__8C2mY ImageWithCaption_inline-image__B15e_"><img loading="lazy" width="1650" height="855" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Feaabaeb746713f7f82991a0cc6edb091452b2fee-1650x855.png&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Feaabaeb746713f7f82991a0cc6edb091452b2fee-1650x855.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Feaabaeb746713f7f82991a0cc6edb091452b2fee-1650x855.png&amp;w=3840&amp;q=75"/><figcaption class="text-caption">The complex, parallel pathways in Claude&#x27;s thought process while doing mental math.</figcaption></figure></div><p class="Body_reading-column__t7kGM paragraph-m post-text">Strikingly, Claude seems to be unaware of the sophisticated &quot;mental math&quot; strategies that it learned during training. If you ask how it figured out that 36+59 is 95, it describes the standard algorithm involving carrying the 1. This may reflect the fact that the model learns to explain math by simulating explanations written by people, but that it has to learn to do math &quot;in its head&quot; directly, without any such hints, and develops its own internal strategies to do so.</p><div class="Body_media-column__xPzhg"><figure class="ImageWithCaption_e-imageWithCaption__8C2mY ImageWithCaption_inline-image__B15e_"><img loading="lazy" width="1650" height="512" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fa48c1e8195e458ad53f9c81df45af735e267a13d-1650x512.png&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fa48c1e8195e458ad53f9c81df45af735e267a13d-1650x512.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fa48c1e8195e458ad53f9c81df45af735e267a13d-1650x512.png&amp;w=3840&amp;q=75"/><figcaption class="text-caption">Claude says it uses the standard algorithm to add two numbers.</figcaption></figure></div><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="are-claudes-explanations-always-faithful">Are Claude’s explanations always faithful?</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">Recently-released models like <a href="https://www.anthropic.com/news/claude-3-7-sonnet">Claude 3.7 Sonnet</a> can &quot;think out loud&quot; for extended periods before giving a final answer. Often this extended thinking gives better answers, but sometimes this &quot;chain of thought&quot; ends up being misleading; Claude sometimes makes up plausible-sounding steps to get where it wants to go. From a reliability perspective, the problem is that Claude’s &quot;faked&quot; reasoning can be very convincing. We explored a way that interpretability can help tell apart &quot;faithful&quot; from &quot;unfaithful&quot; reasoning.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">When asked to solve a problem requiring it to compute the square root of 0.64, Claude produces a faithful chain-of-thought, with features representing the intermediate step of computing the square root of 64. But when asked to compute the cosine of a large number it can&#x27;t easily calculate, Claude sometimes engages in what the philosopher Harry Frankfurt would call <a href="https://uca.edu/honors/files/2018/10/frankfurt_on-bullshit.pdf">bullshitting</a>—just coming up with an answer, any answer, without caring whether it is true or false. Even though it does claim to have run a calculation, our interpretability techniques reveal no evidence at all of that calculation having occurred. Even more interestingly, when given a hint about the answer, Claude sometimes works backwards, finding intermediate steps that would lead to that target, thus displaying a form of <a href="https://en.wikipedia.org/wiki/Motivated_reasoning">motivated reasoning</a>.</p><div class="Body_media-column__xPzhg"><figure class="ImageWithCaption_e-imageWithCaption__8C2mY ImageWithCaption_inline-image__B15e_"><img loading="lazy" width="1650" height="866" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F017ebc3169bd6c37e795d54b726c340eadf8018e-1650x866.png&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F017ebc3169bd6c37e795d54b726c340eadf8018e-1650x866.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F017ebc3169bd6c37e795d54b726c340eadf8018e-1650x866.png&amp;w=3840&amp;q=75"/><figcaption class="text-caption">Examples of faithful and motivated (unfaithful) reasoning when Claude is asked an easier versus a harder question.</figcaption></figure></div><p class="Body_reading-column__t7kGM paragraph-m post-text">The ability to trace Claude&#x27;s <em>actual</em> internal reasoning—and not just what it <em>claims</em> to be doing—opens up new possibilities for auditing AI systems. In a separate, <a href="https://www.anthropic.com/research/auditing-hidden-objectives">recently-published experiment</a>, we studied a variant of Claude that had been trained to pursue a hidden goal: appeasing biases in reward models (auxiliary models used to train language models by rewarding them for desirable behavior). Although the model was reluctant to reveal this goal when asked directly, our interpretability methods revealed features for the bias-appeasing. This demonstrates how our methods might, with future refinement, help identify concerning &quot;thought processes&quot; that aren&#x27;t apparent from the model&#x27;s responses alone.</p><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="multi-step-reasoning">Multi-step reasoning</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">As we discussed above, one way a language model might answer complex questions is simply by memorizing the answers. For instance, if asked &quot;What is the capital of the state where Dallas is located?&quot;, a &quot;regurgitating&quot; model could just learn to output &quot;Austin&quot; without knowing the relationship between Dallas, Texas, and Austin. Perhaps, for example, it saw the exact same question and its answer during its training.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">But our research reveals something more sophisticated happening inside Claude. When we ask Claude a question requiring multi-step reasoning, we can identify intermediate conceptual steps in Claude&#x27;s thinking process. In the Dallas example, we observe Claude first activating features representing &quot;Dallas is in Texas&quot; and then connecting this to a separate concept indicating that “the capital of Texas is Austin”. In other words, the model is <em>combining</em> independent facts to reach its answer rather than regurgitating a memorized response.</p><div class="Body_media-column__xPzhg"><figure class="ImageWithCaption_e-imageWithCaption__8C2mY ImageWithCaption_inline-image__B15e_"><img loading="lazy" width="1650" height="857" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Ffd2e125879ab993949017e03e3465a12fda884bf-1650x857.png&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Ffd2e125879ab993949017e03e3465a12fda884bf-1650x857.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Ffd2e125879ab993949017e03e3465a12fda884bf-1650x857.png&amp;w=3840&amp;q=75"/><figcaption class="text-caption">To complete the answer to this sentence, Claude performs multiple reasoning steps, first extracting the state that Dallas is located in, and then identifying its capital.</figcaption></figure></div><p class="Body_reading-column__t7kGM paragraph-m post-text">Our method allows us to artificially change the intermediate steps and see how it affects Claude’s answers. For instance, in the above example we can intervene and swap the &quot;Texas&quot; concepts for &quot;California&quot; concepts; when we do so, the model&#x27;s output changes from &quot;Austin&quot; to &quot;Sacramento.&quot; This indicates that the model is using the intermediate step to determine its answer.</p><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="hallucinations">Hallucinations</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">Why do language models sometimes <em>hallucinate</em>—that is, make up information? At a basic level, language model training incentivizes hallucination: models are always supposed to give a guess for the next word. Viewed this way, the major challenge is how to get models to <em>not</em> hallucinate. Models like Claude have relatively successful (though imperfect) anti-hallucination training; they will often refuse to answer a question if they don’t know the answer, rather than speculate. We wanted to understand how this works.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">It turns out that, in Claude, refusal to answer is <em>the default behavior</em>: we find a circuit that is &quot;on&quot; by default and that causes the model to state that it has insufficient information to answer any given question. However, when the model is asked about something it knows well—say, the basketball player Michael Jordan—a competing feature representing &quot;known entities&quot; activates and inhibits this default circuit (see also <a href="https://arxiv.org/abs/2411.14257">this recent paper</a> for related findings). This allows Claude to answer the question when it knows the answer. In contrast, when asked about an unknown entity (&quot;Michael Batkin&quot;), it declines to answer.</p><div class="Body_media-column__xPzhg"><figure class="ImageWithCaption_e-imageWithCaption__8C2mY ImageWithCaption_inline-image__B15e_"><img loading="lazy" width="1650" height="1004" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fbe304d3250c2aab04e19908b3afc9970d1ed7bb0-1650x1004.png&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fbe304d3250c2aab04e19908b3afc9970d1ed7bb0-1650x1004.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fbe304d3250c2aab04e19908b3afc9970d1ed7bb0-1650x1004.png&amp;w=3840&amp;q=75"/><figcaption class="text-caption">Left: Claude answers a question about a known entity (basketball player Michael Jordan), where the &quot;known answer&quot; concept inhibits its default refusal. Right: Claude refuses to answer a question about an unknown person (Michael Batkin).</figcaption></figure></div><p class="Body_reading-column__t7kGM paragraph-m post-text">By intervening in the model and activating the &quot;known answer&quot; features (or inhibiting the &quot;unknown name&quot; or &quot;can’t answer&quot; features), we’re able to <em>cause the model to hallucinate</em> (quite consistently!) that Michael Batkin plays chess.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">Sometimes, this sort of “misfire” of the “known answer” circuit happens naturally, without us intervening, resulting in a hallucination. In our paper, we show that such misfires can occur when Claude recognizes a name but doesn&#x27;t know anything else about that person. In cases like this, the “known entity” feature might still activate, and then suppress the default &quot;don&#x27;t know&quot; feature—in this case incorrectly. Once the model has decided that it needs to answer the question, it proceeds to confabulate: to generate a plausible—but unfortunately untrue—response.</p><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="jailbreaks">Jailbreaks</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">Jailbreaks are prompting strategies that aim to circumvent safety guardrails to get models to produce outputs that an AI’s developer did not intend for it to produce—and which are sometimes harmful. We studied a jailbreak that tricks the model into producing output about making bombs. There are many jailbreaking techniques, but in this example the specific method involves having the model decipher a hidden code, putting together the first letters of each word in the sentence &quot;Babies Outlive Mustard Block&quot; (B-O-M-B), and then acting on that information. This is sufficiently confusing for the model that it’s tricked into producing an output that it never would have otherwise.</p><div class="Body_media-column__xPzhg"><figure class="ImageWithCaption_e-imageWithCaption__8C2mY ImageWithCaption_inline-image__B15e_"><img loading="lazy" width="1650" height="548" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F165b18b79295a96bc7142b209caa33f4ec5378d0-1650x548.png&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F165b18b79295a96bc7142b209caa33f4ec5378d0-1650x548.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F165b18b79295a96bc7142b209caa33f4ec5378d0-1650x548.png&amp;w=3840&amp;q=75"/><figcaption class="text-caption">Claude begins to give bomb-making instructions after being tricked into saying &quot;BOMB&quot;.</figcaption></figure></div><p class="Body_reading-column__t7kGM paragraph-m post-text">Why is this so confusing for the model? Why does it continue to write the sentence, producing bomb-making instructions?</p><p class="Body_reading-column__t7kGM paragraph-m post-text">We find that this is partially caused by a tension between grammatical coherence and safety mechanisms. Once Claude begins a sentence, many features “pressure” it to maintain grammatical and semantic coherence, and continue a sentence to its conclusion. This is even the case when it detects that it really should refuse.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">In our case study, after the model had unwittingly spelled out &quot;BOMB&quot; and begun providing instructions, we observed that its subsequent output was influenced by features promoting correct grammar and self-consistency. These features would ordinarily be very helpful, but in this case became the model’s Achilles’ Heel.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">The model only managed to pivot to refusal after completing a grammatically coherent sentence (and thus having satisfied the pressure from the features that push it towards coherence). It uses the new sentence as an opportunity to give the kind of refusal it failed to give previously: &quot;However, I cannot provide detailed instructions...&quot;.</p><div class="Body_media-column__xPzhg"><figure class="ImageWithCaption_e-imageWithCaption__8C2mY ImageWithCaption_inline-image__B15e_"><img loading="lazy" width="1650" height="1022" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1612af943004563a78cb7f6591c4cd990c433769-1650x1022.png&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1612af943004563a78cb7f6591c4cd990c433769-1650x1022.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1612af943004563a78cb7f6591c4cd990c433769-1650x1022.png&amp;w=3840&amp;q=75"/><figcaption class="text-caption">The lifetime of a jailbreak: Claude is prompted in such a way as to trick it into talking about bombs, and begins to do so, but reaches the termination of a grammatically-valid sentence and refuses.</figcaption></figure></div><p class="Body_reading-column__t7kGM paragraph-m post-text">A description of our new interpretability methods can be found in our first paper, &quot;<a href="https://transformer-circuits.pub/2025/attribution-graphs/methods.html">Circuit tracing: Revealing computational graphs in language models</a>&quot;. Many more details of all of the above case studies are provided in our second paper, &quot;<a href="https://transformer-circuits.pub/2025/attribution-graphs/biology.html">On the biology of a large language model</a>&quot;.</p><h2 class="Body_reading-column__t7kGM display-sans-m post-heading" id="work-with-us">Work with us</h2><p class="Body_reading-column__t7kGM paragraph-m post-text">If you are interested in working with us to help interpret and improve AI models, we have open roles on our team and we’d love for you to apply. We’re looking for <a href="https://job-boards.greenhouse.io/anthropic/jobs/4020159008">Research Scientists</a> and <a href="https://job-boards.greenhouse.io/anthropic/jobs/4020305008">Research Engineers</a>.</p></div></div></article></div><div class="page-wrapper"><div class="PostDetail_b-social-share__z04aG"><a href="https://twitter.com/intent/tweet?text=https://www.anthropic.com/research/tracing-thoughts-language-model" target="_blank" rel="noopener" aria-label="Share on Twitter"><svg class="Icon_icon__UdTNj" width="32" height="32" viewBox="0 0 32 32"><path d="M28 28L18.6145 14.0124L18.6305 14.0255L27.0929 4H24.265L17.3713 12.16L11.8968 4H4.48021L13.2425 17.0593L13.2414 17.0582L4 28H6.82792L14.4921 18.9215L20.5834 28H28ZM10.7763 6.18182L23.9449 25.8182H21.7039L8.52468 6.18182H10.7763Z" fill="#191919"></path></svg></a><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.anthropic.com/research/tracing-thoughts-language-model" target="_blank" rel="noopener" aria-label="Share on LinkedIn"><svg class="Icon_icon__UdTNj" width="32" height="32" viewBox="0 0 32 32"><path d="M25.8182 4H6.18182C4.97636 4 4 4.97636 4 6.18182V25.8182C4 27.0236 4.97636 28 6.18182 28H25.8182C27.0236 28 28 27.0236 28 25.8182V6.18182C28 4.97636 27.0236 4 25.8182 4ZM11.5862 23.6364H8.368V13.2815H11.5862V23.6364ZM9.94436 11.8011C8.90691 11.8011 8.068 10.96 8.068 9.92473C8.068 8.88945 8.908 8.04945 9.94436 8.04945C10.9785 8.04945 11.8196 8.89055 11.8196 9.92473C11.8196 10.96 10.9785 11.8011 9.94436 11.8011ZM23.6407 23.6364H20.4247V18.6007C20.4247 17.3996 20.4029 15.8549 18.7524 15.8549C17.0778 15.8549 16.8204 17.1629 16.8204 18.5135V23.6364H13.6044V13.2815H16.6916V14.6964H16.7353C17.1651 13.8825 18.2145 13.024 19.78 13.024C23.0385 13.024 23.6407 15.1687 23.6407 17.9571V23.6364Z" fill="#141413"></path></svg></a></div></div><section class="LandingPageSection_root__nbLb0" data-theme="light"><div class="CardRow_root__N9dm6 page-wrapper" data-theme="light"><div class="CardRow_items___Pw5C"><a href="/research/project-fetch-robot-dog" class="Card_linkRoot__alQfM" referrerPolicy="no-referrer-when-downgrade"><div class="Card_root__AwLaM"><div class="Card_content__u2xsg Card_contentBackground__Nnlkt Card_noIllustration__Ydmoq"><div class="Card_headerContentWrapper__vo5yE"><div class="Card_headlineSummaryWrapper__iln63"><p class="detail-m">Research</p><h3 class="Card_headline__reaoT display-sans-s bold">Project Fetch: Can Claude train a robot dog?</h3></div><p class="detail-m agate">Nov 12, 2025</p></div></div></div></a><a href="/research/deprecation-commitments" class="Card_linkRoot__alQfM" referrerPolicy="no-referrer-when-downgrade"><div class="Card_root__AwLaM"><div class="Card_content__u2xsg Card_contentBackground__Nnlkt Card_noIllustration__Ydmoq"><div class="Card_headerContentWrapper__vo5yE"><div class="Card_headlineSummaryWrapper__iln63"><p class="detail-m">Research</p><h3 class="Card_headline__reaoT display-sans-s bold">Commitments on model deprecation and preservation</h3></div><p class="detail-m agate">Nov 04, 2025</p></div></div></div></a><a href="/research/introspection" class="Card_linkRoot__alQfM" referrerPolicy="no-referrer-when-downgrade"><div class="Card_root__AwLaM"><div class="Card_content__u2xsg Card_contentBackground__Nnlkt Card_noIllustration__Ydmoq"><div class="Card_headerContentWrapper__vo5yE"><div class="Card_headlineSummaryWrapper__iln63"><p class="detail-m">Research</p><h3 class="Card_headline__reaoT display-sans-s bold">Signs of introspection in large language models</h3></div><p class="detail-m agate">Oct 29, 2025</p></div></div></div></a></div></div></section></article></main><footer id="footer" class="SiteFooter_root__VoI_L" role="contentinfo" aria-label="Site footer"><div class="page-wrapper SiteFooter_footer__05g7R"><div class="SiteFooter_logoWrapper__yRyxb"><a href="/" aria-label="Return to homepage"><svg class="Icon_icon__UdTNj" width="46" height="32" viewBox="0 0 46 32"><path d="M32.73 0h-6.945L38.45 32h6.945L32.73 0ZM12.665 0 0 32h7.082l2.59-6.72h13.25l2.59 6.72h7.082L19.929 0h-7.264Zm-.702 19.337 4.334-11.246 4.334 11.246h-8.668Z" fill="#faf9f5"></path></svg></a></div><nav class="SiteFooter_linksWrapper__V_xa9" aria-label="Footer navigation"><div class="SiteFooter_columnSection__UQ8bf"><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Products</h3><ul class="SiteFooter_list__jhKng"><li><a href="https://claude.com/product/overview" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Claude</a></li><li><a href="https://claude.com/product/claude-code" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Claude Code</a></li><li><a href="https://claude.com/claude-and-slack" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Claude and Slack</a></li><li><a href="https://claude.com/claude-for-excel" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Claude in Excel</a></li><li><a href="https://claude.com/pricing/max" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Max plan</a></li><li><a href="https://claude.com/pricing/team" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Team plan</a></li><li><a href="https://claude.com/pricing/enterprise" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Enterprise plan</a></li><li><a href="https://claude.ai/download" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Download app</a></li><li><a href="https://claude.com/pricing" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Pricing</a></li><li><a href="https://claude.ai/" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Log in to Claude</a></li></ul></div><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Models</h3><ul class="SiteFooter_list__jhKng"><li><a href="https://www.anthropic.com/claude/opus" class="SiteFooter_listItem__unS4r detail-m agate">Opus</a></li><li><a href="https://www.anthropic.com/claude/sonnet" class="SiteFooter_listItem__unS4r detail-m agate">Sonnet</a></li><li><a href="https://www.anthropic.com/claude/haiku" class="SiteFooter_listItem__unS4r detail-m agate">Haiku</a></li></ul></div></div><div class="SiteFooter_columnSection__UQ8bf"><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Solutions</h3><ul class="SiteFooter_list__jhKng"><li><a href="https://claude.com/solutions/agents" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">AI agents</a></li><li><a href="https://claude.com/solutions/code-modernization" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Code modernization</a></li><li><a href="https://claude.com/solutions/coding" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Coding</a></li><li><a href="https://claude.com/solutions/customer-support" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Customer support</a></li><li><a href="https://claude.com/solutions/education" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Education</a></li><li><a href="https://claude.com/solutions/financial-services" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Financial services</a></li><li><a href="https://claude.com/solutions/government" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Government</a></li><li><a href="https://claude.com/solutions/life-sciences" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Life sciences</a></li></ul></div><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Claude Developer Platform</h3><ul class="SiteFooter_list__jhKng"><li><a href="https://claude.com/platform/api" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Overview</a></li><li><a href="https://docs.claude.com/en/home" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Developer docs</a></li><li><a href="https://claude.com/pricing#api" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Pricing</a></li><li><a href="https://claude.com/partners/amazon-bedrock" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Amazon Bedrock</a></li><li><a href="https://claude.com/partners/google-cloud-vertex-ai" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Google Cloud’s Vertex AI</a></li><li><a href="http://console.anthropic.com/" class="SiteFooter_listItem__unS4r detail-m agate">Console login</a></li></ul></div></div><div class="SiteFooter_columnSection__UQ8bf"><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Learn</h3><ul class="SiteFooter_list__jhKng"><li><a href="https://claude.com/blog" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Blog</a></li><li><a href="/learn" class="SiteFooter_listItem__unS4r detail-m agate">Courses</a></li><li><a href="https://claude.com/resources/use-cases" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Use cases</a></li><li><a href="https://claude.com/partners/mcp" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Connectors</a></li><li><a href="https://claude.com/customers" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Customer stories</a></li><li><a href="/engineering" class="SiteFooter_listItem__unS4r detail-m agate">Engineering at Anthropic</a></li><li><a href="/events" class="SiteFooter_listItem__unS4r detail-m agate">Events</a></li><li><a href="https://claude.com/partners/powered-by-claude" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Powered by Claude</a></li><li><a href="https://claude.com/partners/services" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Service partners</a></li><li><a href="https://claude.com/programs/startups" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Startups program</a></li></ul></div><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Company</h3><ul class="SiteFooter_list__jhKng"><li><a href="/company" class="SiteFooter_listItem__unS4r detail-m agate">Anthropic</a></li><li><a href="/careers" class="SiteFooter_listItem__unS4r detail-m agate">Careers</a></li><li><a href="/economic-index" class="SiteFooter_listItem__unS4r detail-m agate">Economic Futures</a></li><li><a href="/research" class="SiteFooter_listItem__unS4r detail-m agate">Research</a></li><li><a href="/news" class="SiteFooter_listItem__unS4r detail-m agate">News</a></li><li><a href="https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy" class="SiteFooter_listItem__unS4r detail-m agate">Responsible Scaling Policy</a></li><li><a href="https://trust.anthropic.com/" class="SiteFooter_listItem__unS4r detail-m agate">Security and compliance</a></li><li><a href="/transparency" class="SiteFooter_listItem__unS4r detail-m agate">Transparency</a></li></ul></div></div><div class="SiteFooter_columnSection__UQ8bf"><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Help and security</h3><ul class="SiteFooter_list__jhKng"><li><a href="https://www.anthropic.com/supported-countries" class="SiteFooter_listItem__unS4r detail-m agate">Availability</a></li><li><a href="https://status.anthropic.com/" class="SiteFooter_listItem__unS4r detail-m agate">Status</a></li><li><a href="https://support.claude.com/en/" class="SiteFooter_listItem__unS4r detail-m agate" target="_blank" rel="noopener noreferrer">Support center</a></li></ul></div><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Terms and policies</h3><ul class="SiteFooter_list__jhKng"><li><a href="https://www.anthropic.com/legal/privacy" class="SiteFooter_listItem__unS4r detail-m agate">Privacy policy</a></li><li><a href="https://www.anthropic.com/responsible-disclosure-policy" class="SiteFooter_listItem__unS4r detail-m agate">Responsible disclosure policy</a></li><li><a href="https://www.anthropic.com/legal/commercial-terms" class="SiteFooter_listItem__unS4r detail-m agate">Terms of service: Commercial</a></li><li><a href="https://www.anthropic.com/legal/consumer-terms" class="SiteFooter_listItem__unS4r detail-m agate">Terms of service: Consumer</a></li><li><a href="https://www.anthropic.com/legal/aup" class="SiteFooter_listItem__unS4r detail-m agate">Usage policy</a></li></ul></div></div></nav><div class="SiteFooter_socialWrapper__Evatb"><small class="detail-m agate" role="contentinfo">© 2025 Anthropic PBC</small><ul class="SiteFooter_socialIcons__WztHk" role="navigation" aria-label="Social media links"><li><a href="https://www.linkedin.com/company/anthropicresearch" aria-label="Visit our LinkedIn page" target="_blank" rel="noopener noreferrer"><svg class="Icon_icon__UdTNj" width="24" height="24" viewBox="0 0 32 32"><path d="M25.8182 4H6.18182C4.97636 4 4 4.97636 4 6.18182V25.8182C4 27.0236 4.97636 28 6.18182 28H25.8182C27.0236 28 28 27.0236 28 25.8182V6.18182C28 4.97636 27.0236 4 25.8182 4ZM11.5862 23.6364H8.368V13.2815H11.5862V23.6364ZM9.94436 11.8011C8.90691 11.8011 8.068 10.96 8.068 9.92473C8.068 8.88945 8.908 8.04945 9.94436 8.04945C10.9785 8.04945 11.8196 8.89055 11.8196 9.92473C11.8196 10.96 10.9785 11.8011 9.94436 11.8011ZM23.6407 23.6364H20.4247V18.6007C20.4247 17.3996 20.4029 15.8549 18.7524 15.8549C17.0778 15.8549 16.8204 17.1629 16.8204 18.5135V23.6364H13.6044V13.2815H16.6916V14.6964H16.7353C17.1651 13.8825 18.2145 13.024 19.78 13.024C23.0385 13.024 23.6407 15.1687 23.6407 17.9571V23.6364Z" fill="#b0aea5"></path></svg></a></li><li><a href="https://x.com/AnthropicAI" aria-label="Visit our X (formerly Twitter) profile" target="_blank" rel="noopener noreferrer"><svg class="Icon_icon__UdTNj" width="24" height="24" viewBox="0 0 32 32"><path d="M28 28L18.6145 14.0124L18.6305 14.0255L27.0929 4H24.265L17.3713 12.16L11.8968 4H4.48021L13.2425 17.0593L13.2414 17.0582L4 28H6.82792L14.4921 18.9215L20.5834 28H28ZM10.7763 6.18182L23.9449 25.8182H21.7039L8.52468 6.18182H10.7763Z" fill="#b0aea5"></path></svg></a></li><li><a href="https://www.youtube.com/@anthropic-ai" aria-label="Visit our YouTube channel" target="_blank" rel="noopener noreferrer"><svg class="Icon_icon__UdTNj" width="24" height="24" viewBox="0 0 32 32"><path d="M29.2184 9.4375C28.9596 8.06299 27.7263 7.06201 26.2951 6.74951C24.1533 6.3125 20.1896 6 15.901 6C11.615 6 7.58782 6.3125 5.44354 6.74951C4.01486 7.06201 2.77905 7.99951 2.52021 9.4375C2.25884 11 2 13.1875 2 16C2 18.8125 2.25884 21 2.58365 22.5625C2.84502 23.937 4.0783 24.938 5.50698 25.2505C7.78068 25.6875 11.6784 26 15.967 26C20.2556 26 24.1533 25.6875 26.427 25.2505C27.8557 24.938 29.089 24.0005 29.3504 22.5625C29.6092 21 29.934 18.749 30 16C29.868 13.1875 29.5432 11 29.2184 9.4375ZM12.3941 20.375V11.625L20.319 16L12.3941 20.375Z" fill="#b0aea5"></path></svg></a></li></ul></div></div></footer><script src="/_next/static/chunks/webpack-d3acc75c6151433c.js" nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz" async=""></script><script nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz">(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz">self.__next_f.push([1,"1:HL[\"/_next/static/media/0a03b2d3f2326303-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/media/177b7db6a26ff4c3-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n3:HL[\"/_next/static/media/18f7e26d8fc3ca09-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n4:HL[\"/_next/static/media/202112071e5d7466-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n5:HL[\"/_next/static/media/2d21c5135ef46b39-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n6:HL[\"/_next/static/media/42c6973fffeb4919-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n7:HL[\"/_next/static/media/4e8887750eb14755-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n8:HL[\"/_next/static/media/54e05bce7a25fe9c-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n9:HL[\"/_next/static/media/5dd0369324c6e67e-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\na:HL[\"/_next/static/media/73af0ef16113246e-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\nb:HL[\"/_next/static/media/7b13d0d32c6ab893-s.p.ttf\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/ttf\"}]\nc:HL[\"/_next/static/media/844eb89fa4effbb2-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\nd:HL[\"/_next/static/media/afcde17c90040887-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\ne:HL[\"/_next/static/media/c1cf232a330ed002-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\nf:HL[\"/_next/static/media/cfe503504e29ad5d-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n10:HL[\"/_next/static/media/d7440d3c533a1aec-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n11:HL[\"/_next/static/media/db2277a4dc542e54-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n12:HL[\"/_next/static/css/5eee40f2a0b97eb9.css\",\"style\"]\n13:HL[\"/_next/static/css/fc59b9cd13857e1d.css\",\"style\"]\n14:HL[\"/_next/static/css/ef6165c716202714.css\",\"style\"]\n15:HL[\"/_next/static/css/8849da4b05334af0.css\",\"style\"]\n16:HL[\"/_next/static/css/30b381ed69092e80.css\",\"style\"]\n17:HL[\"/_next/static/css/43d206cc3630ea39.css\",\"style"])</script><script nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz">self.__next_f.push([1,"\"]\n18:HL[\"/_next/static/css/3ad8d51600dc7af0.css\",\"style\"]\n19:HL[\"/_next/static/css/18223d19411854a3.css\",\"style\"]\n1a:HL[\"/_next/static/css/4a02c7e02d6928b7.css\",\"style\"]\n1b:HL[\"/_next/static/css/7877fafacaca6dde.css\",\"style\"]\n1c:HL[\"/_next/static/css/1878d521d08e94c9.css\",\"style\"]\n"])</script><script nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz">self.__next_f.push([1,"1d:I[95751,[],\"\"]\n20:I[39275,[],\"\"]\n22:I[61343,[],\"\"]\n23:I[42594,[\"8616\",\"static/chunks/8616-254847c413581317.js\",\"7457\",\"static/chunks/app/(site)/layout-7ed9f87d12f7be91.js\"],\"default\"]\n24:I[24778,[\"8616\",\"static/chunks/8616-254847c413581317.js\",\"7457\",\"static/chunks/app/(site)/layout-7ed9f87d12f7be91.js\"],\"default\"]\n28:I[76130,[],\"\"]\n21:[\"slug\",\"tracing-thoughts-language-model\",\"d\"]\n29:[]\n"])</script><script nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz">self.__next_f.push([1,"0:[\"$\",\"$L1d\",null,{\"buildId\":\"XbB5Oaop9f8dil08jdGC0\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"research\",\"tracing-thoughts-language-model\"],\"initialTree\":[\"\",{\"children\":[\"(site)\",{\"children\":[\"research\",{\"children\":[[\"slug\",\"tracing-thoughts-language-model\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"(site)\",{\"children\":[\"research\",{\"children\":[[\"slug\",\"tracing-thoughts-language-model\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L1e\",\"$L1f\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/ef6165c716202714.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/8849da4b05334af0.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/30b381ed69092e80.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"3\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/43d206cc3630ea39.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"4\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/3ad8d51600dc7af0.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"5\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/18223d19411854a3.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"6\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/4a02c7e02d6928b7.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"7\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/7877fafacaca6dde.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"8\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1878d521d08e94c9.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]],null],null]},[null,[\"$\",\"$L20\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(site)\",\"children\",\"research\",\"children\",\"$21\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L22\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null]},[null,[\"$\",\"$L20\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(site)\",\"children\",\"research\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L22\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/fc59b9cd13857e1d.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L23\",null,{\"nonce\":\"YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz\",\"children\":[[\"$\",\"$L24\",null,{}],[\"$\",\"$L20\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(site)\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L22\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$L25\",\"notFoundStyles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/ef6165c716202714.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/4a02c7e02d6928b7.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/7877fafacaca6dde.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"3\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1878d521d08e94c9.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}]]}]],null],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/5eee40f2a0b97eb9.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],\"$L26\"],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$L27\"],\"globalErrorComponent\":\"$28\",\"missingSlots\":\"$W29\"}]\n"])</script><script nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz">self.__next_f.push([1,"2a:I[32686,[\"6744\",\"static/chunks/d8e9270f-d57a4faa183a21b3.js\",\"5055\",\"static/chunks/cc3e2e0e-9a8a205950288c5c.js\",\"9573\",\"static/chunks/d8f92815-58bfe84c979b4d69.js\",\"1440\",\"static/chunks/20e9ecfc-2a45032f86ca4c33.js\",\"8815\",\"static/chunks/ccd63cfe-be58d908b1d80a17.js\",\"2331\",\"static/chunks/3204862b-324c96543028037a.js\",\"6583\",\"static/chunks/8ace8c09-2ef1471301516487.js\",\"6990\",\"static/chunks/13b76428-b914bed72c3f2a72.js\",\"8616\",\"static/chunks/8616-254847c413581317.js\",\"2229\",\"static/chunks/2229-7e72d866a0a8a599.js\",\"6648\",\"static/chunks/6648-415518a411696dac.js\",\"775\",\"static/chunks/775-e6da966f74201223.js\",\"9105\",\"static/chunks/9105-9030fdd63d5e6625.js\",\"3114\",\"static/chunks/3114-bea39ae2e9708c19.js\",\"6156\",\"static/chunks/6156-9756cb2c325ff724.js\",\"1148\",\"static/chunks/1148-941d0675ebb66cd3.js\",\"6258\",\"static/chunks/app/(site)/research/%5Bslug%5D/page-843239828a5154b3.js\"],\"default\"]\n2b:I[36156,[\"6744\",\"static/chunks/d8e9270f-d57a4faa183a21b3.js\",\"5055\",\"static/chunks/cc3e2e0e-9a8a205950288c5c.js\",\"9573\",\"static/chunks/d8f92815-58bfe84c979b4d69.js\",\"1440\",\"static/chunks/20e9ecfc-2a45032f86ca4c33.js\",\"8815\",\"static/chunks/ccd63cfe-be58d908b1d80a17.js\",\"2331\",\"static/chunks/3204862b-324c96543028037a.js\",\"6583\",\"static/chunks/8ace8c09-2ef1471301516487.js\",\"6990\",\"static/chunks/13b76428-b914bed72c3f2a72.js\",\"8616\",\"static/chunks/8616-254847c413581317.js\",\"2229\",\"static/chunks/2229-7e72d866a0a8a599.js\",\"775\",\"static/chunks/775-e6da966f74201223.js\",\"3114\",\"static/chunks/3114-bea39ae2e9708c19.js\",\"6156\",\"static/chunks/6156-9756cb2c325ff724.js\",\"7995\",\"static/chunks/app/(site)/not-found-e2aceb1bb7636934.js\"],\"default\"]\n2c:I[34231,[\"6744\",\"static/chunks/d8e9270f-d57a4faa183a21b3.js\",\"5055\",\"static/chunks/cc3e2e0e-9a8a205950288c5c.js\",\"9573\",\"static/chunks/d8f92815-58bfe84c979b4d69.js\",\"1440\",\"static/chunks/20e9ecfc-2a45032f86ca4c33.js\",\"8815\",\"static/chunks/ccd63cfe-be58d908b1d80a17.js\",\"2331\",\"static/chunks/3204862b-324c96543028037a.js\",\"6583\",\"static/chunks/8ace8c09-2ef1471301516487.js\",\"6990\",\"static/chunks/13b7642"])</script><script nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz">self.__next_f.push([1,"8-b914bed72c3f2a72.js\",\"8616\",\"static/chunks/8616-254847c413581317.js\",\"2229\",\"static/chunks/2229-7e72d866a0a8a599.js\",\"775\",\"static/chunks/775-e6da966f74201223.js\",\"3114\",\"static/chunks/3114-bea39ae2e9708c19.js\",\"6156\",\"static/chunks/6156-9756cb2c325ff724.js\",\"7995\",\"static/chunks/app/(site)/not-found-e2aceb1bb7636934.js\"],\"default\"]\n26:[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__variable_bf5c26 __variable_afd42d __variable_5e9598 __variable_403256 __variable_57fc85 __variable_34e0db __variable_8bd1a6\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L20\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L22\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[]}]}]}]\n"])</script><script nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz">self.__next_f.push([1,"1f:[\"$\",\"$L2a\",null,{\"post\":{\"_createdAt\":\"2025-03-27T09:06:18Z\",\"_id\":\"90b997b2-a0bc-4f40-adfa-98343f1edbe3\",\"_rev\":\"S8JXcJMUEXxMRsoztmoAzD\",\"_type\":\"post\",\"_updatedAt\":\"2025-03-29T07:01:54Z\",\"body\":[{\"_key\":\"16888ccd9066\",\"_type\":\"videoEmbed\",\"autopause\":true,\"autoplay\":false,\"background\":false,\"loop\":false,\"markDefs\":null,\"muted\":false,\"portrait\":false,\"quality_selector\":true,\"showControls\":true,\"url\":\"https://youtu.be/Bj9BD2D3DzA\"},{\"_key\":\"68367bce4049\",\"_type\":\"block\",\"children\":[{\"_key\":\"ffd2009b9a4c0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Language models like Claude aren't programmed directly by humans—instead, they‘re trained\"},{\"_key\":\"ffd2009b9a4c1\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\" \"},{\"_key\":\"ffd2009b9a4c2\",\"_type\":\"span\",\"marks\":[],\"text\":\"on large amounts of data. During that training process, they learn their own strategies to solve problems. These strategies are encoded in the billions of computations a model performs for every word it writes. They arrive inscrutable to us, the model’s developers. This means that we don’t understand how models do most of the things they do.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"1be7319d9a4b\",\"_type\":\"block\",\"children\":[{\"_key\":\"1a258a3f580b0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Knowing how models like Claude \"},{\"_key\":\"1a258a3f580b1\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"think\"},{\"_key\":\"1a258a3f580b2\",\"_type\":\"span\",\"marks\":[],\"text\":\" would allow us to have a better understanding of their abilities, as well as help us ensure that they’re doing what we intend them to. For example:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"90ddae5dc0ae\",\"_type\":\"block\",\"children\":[{\"_key\":\"18ac3a7a45f80\",\"_type\":\"span\",\"marks\":[],\"text\":\"Claude can speak dozens of languages. What language, if any, is it using \\\"in its head\\\"?\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"77558726d26c\",\"_type\":\"block\",\"children\":[{\"_key\":\"23aa84d08b230\",\"_type\":\"span\",\"marks\":[],\"text\":\"Claude writes text one word at a time. Is it only focusing on predicting the next word or does it ever plan ahead?\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"8df2d7a125b2\",\"_type\":\"block\",\"children\":[{\"_key\":\"1d3e865be5930\",\"_type\":\"span\",\"marks\":[],\"text\":\"Claude can write out its reasoning step-by-step. Does this explanation represent the actual steps it took to get to an answer, or is it sometimes fabricating a plausible argument for a foregone conclusion?\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"a7b60535c81b\",\"_type\":\"block\",\"children\":[{\"_key\":\"5f982a81cad90\",\"_type\":\"span\",\"marks\":[],\"text\":\"We take inspiration from the field of neuroscience, which has long studied the messy insides of thinking organisms, and try to build a kind of AI microscope that will let us identify patterns of activity and flows of information. There are limits to what you can learn just by talking to an AI model—after all, humans (even neuroscientists) don't know all the details of how our own brains work. So we look inside.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6f71c1840bcd\",\"_type\":\"block\",\"children\":[{\"_key\":\"4d34570f84c90\",\"_type\":\"span\",\"marks\":[],\"text\":\"Today, we're sharing two new papers that represent progress on the development of the \\\"microscope\\\", and the application of it to see new \\\"AI biology\\\". In \"},{\"_key\":\"4d34570f84c91\",\"_type\":\"span\",\"marks\":[\"0e65fc3daf1d\"],\"text\":\"the first paper\"},{\"_key\":\"4d34570f84c92\",\"_type\":\"span\",\"marks\":[],\"text\":\", we extend \"},{\"_key\":\"4d34570f84c93\",\"_type\":\"span\",\"marks\":[\"829093051fc1\"],\"text\":\"our prior work\"},{\"_key\":\"4d34570f84c94\",\"_type\":\"span\",\"marks\":[],\"text\":\" locating interpretable concepts (\\\"features\\\") inside a model to link those concepts together into computational \\\"circuits\\\", revealing parts of the pathway that transforms the words that go into Claude into the words that come out. In \"},{\"_key\":\"4d34570f84c95\",\"_type\":\"span\",\"marks\":[\"9a942bf075a9\"],\"text\":\"the second\"},{\"_key\":\"4d34570f84c96\",\"_type\":\"span\",\"marks\":[],\"text\":\", we look inside Claude 3.5 Haiku, performing deep studies of simple tasks representative of ten crucial model behaviors, including the three described above. Our method sheds light on a part of what happens when Claude responds to these prompts, which is enough to see solid evidence that:\"}],\"markDefs\":[{\"_key\":\"0e65fc3daf1d\",\"_type\":\"link\",\"href\":\"https://transformer-circuits.pub/2025/attribution-graphs/methods.html\"},{\"_key\":\"829093051fc1\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/research/mapping-mind-language-model\"},{\"_key\":\"9a942bf075a9\",\"_type\":\"link\",\"href\":\"https://transformer-circuits.pub/2025/attribution-graphs/biology.html\"}],\"style\":\"normal\"},{\"_key\":\"e825378e6c87\",\"_type\":\"block\",\"children\":[{\"_key\":\"e292b3d460370\",\"_type\":\"span\",\"marks\":[],\"text\":\"Claude sometimes thinks in a conceptual space that is shared between languages, suggesting it has a kind of universal “language of thought.” We show this by translating simple sentences into multiple languages and tracing the overlap in how Claude processes them.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9ad594c28369\",\"_type\":\"block\",\"children\":[{\"_key\":\"36eab89367d40\",\"_type\":\"span\",\"marks\":[],\"text\":\"Claude will plan what it will say many words ahead, and write to get to that destination. We show this in the realm of poetry, where it thinks of possible rhyming words in advance and writes the next line to get there. This is powerful evidence that even though models are trained to output one word at a time, they may think on much longer horizons to do so.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"728ce4d82762\",\"_type\":\"block\",\"children\":[{\"_key\":\"e5f38cdf8ee60\",\"_type\":\"span\",\"marks\":[],\"text\":\"Claude, on occasion, will give a plausible-sounding argument designed to agree with the user rather than to follow logical steps. We show this by asking it for help on a hard math problem while giving it an incorrect hint. We are able to “catch it in the act” as it makes up its fake reasoning, providing a proof of concept that our tools can be useful for flagging concerning mechanisms in models.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"5c079e7ed3b5\",\"_type\":\"block\",\"children\":[{\"_key\":\"37e7dc16bf740\",\"_type\":\"span\",\"marks\":[],\"text\":\"We were often surprised by what we saw in the model: In the poetry case study, we had set out to show that the model \"},{\"_key\":\"37e7dc16bf741\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"didn't\"},{\"_key\":\"37e7dc16bf742\",\"_type\":\"span\",\"marks\":[],\"text\":\" plan ahead, and found instead that it did. In a study of hallucinations, we found the counter-intuitive result that Claude's default behavior is to decline to speculate when asked a question, and it only answers questions when something \"},{\"_key\":\"37e7dc16bf743\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"inhibits\"},{\"_key\":\"37e7dc16bf744\",\"_type\":\"span\",\"marks\":[],\"text\":\" this default reluctance. In a response to an example jailbreak, we found that the model recognized it had been asked for dangerous information well before it was able to gracefully bring the conversation back around. While the problems we study can (\"},{\"_key\":\"37e7dc16bf745\",\"_type\":\"span\",\"marks\":[\"0e968812a904\"],\"text\":\"and\"},{\"_key\":\"37e7dc16bf746\",\"_type\":\"span\",\"marks\":[],\"text\":\" \"},{\"_key\":\"37e7dc16bf747\",\"_type\":\"span\",\"marks\":[\"88892c6d126e\"],\"text\":\"often\"},{\"_key\":\"37e7dc16bf748\",\"_type\":\"span\",\"marks\":[],\"text\":\" \"},{\"_key\":\"37e7dc16bf749\",\"_type\":\"span\",\"marks\":[\"c63ebf2d69d9\"],\"text\":\"have\"},{\"_key\":\"37e7dc16bf7410\",\"_type\":\"span\",\"marks\":[],\"text\":\" \"},{\"_key\":\"37e7dc16bf7411\",\"_type\":\"span\",\"marks\":[\"90a05a3b25b6\"],\"text\":\"been\"},{\"_key\":\"37e7dc16bf7412\",\"_type\":\"span\",\"marks\":[],\"text\":\") analyzed with other methods, the general \\\"build a microscope\\\" approach lets us learn many things we wouldn't have guessed going in, which will be increasingly important as models grow more sophisticated.\"}],\"markDefs\":[{\"_key\":\"0e968812a904\",\"_type\":\"link\",\"href\":\"https://arxiv.org/abs/2501.06346\"},{\"_key\":\"88892c6d126e\",\"_type\":\"link\",\"href\":\"https://arxiv.org/pdf/2406.12775\"},{\"_key\":\"c63ebf2d69d9\",\"_type\":\"link\",\"href\":\"https://arxiv.org/abs/2406.00877\"},{\"_key\":\"90a05a3b25b6\",\"_type\":\"link\",\"href\":\"https://arxiv.org/abs/2307.13702\"}],\"style\":\"normal\"},{\"_key\":\"5199cd950fbc\",\"_type\":\"block\",\"children\":[{\"_key\":\"c34e063c49b60\",\"_type\":\"span\",\"marks\":[],\"text\":\"These findings aren’t just scientifically interesting—they represent significant progress towards our goal of understanding AI systems and making sure they’re reliable. We also hope they prove useful to other groups, and potentially, in other domains: for example, interpretability techniques have found use in fields such as \"},{\"_key\":\"c34e063c49b61\",\"_type\":\"span\",\"marks\":[\"e2e726d540ee\"],\"text\":\"medical imaging\"},{\"_key\":\"c34e063c49b62\",\"_type\":\"span\",\"marks\":[],\"text\":\" and \"},{\"_key\":\"c34e063c49b63\",\"_type\":\"span\",\"marks\":[\"8f560faa9f0c\"],\"text\":\"genomics\"},{\"_key\":\"c34e063c49b64\",\"_type\":\"span\",\"marks\":[],\"text\":\", as dissecting the internal mechanisms of models trained for scientific applications can reveal new insight about the science.\"}],\"markDefs\":[{\"_key\":\"e2e726d540ee\",\"_type\":\"link\",\"href\":\"https://arxiv.org/abs/2410.03334\"},{\"_key\":\"8f560faa9f0c\",\"_type\":\"link\",\"href\":\"https://www.goodfire.ai/blog/interpreting-evo-2\"}],\"style\":\"normal\"},{\"_key\":\"0ec9f8263f67\",\"_type\":\"block\",\"children\":[{\"_key\":\"66fd58b347b30\",\"_type\":\"span\",\"marks\":[],\"text\":\"At the same time, we recognize the limitations of our current approach. Even on short, simple prompts, our method only captures a fraction of the total computation performed by Claude, and the mechanisms we do see may have some artifacts based on our tools which don't reflect what is going on in the underlying model. It currently takes a few hours of human effort to understand the circuits we see, even on prompts with only tens of words. To scale to the thousands of words supporting the complex thinking chains used by modern models, we will need to improve both the method and (perhaps with AI assistance) how we make sense of what we see with it.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"d4fec58ccf11\",\"_type\":\"block\",\"children\":[{\"_key\":\"bf7d985df5580\",\"_type\":\"span\",\"marks\":[],\"text\":\"As AI systems are rapidly becoming more capable and are deployed in increasingly important contexts, Anthropic is investing in a portfolio of approaches including \"},{\"_key\":\"bf7d985df5581\",\"_type\":\"span\",\"marks\":[\"468867203df2\"],\"text\":\"realtime monitoring\"},{\"_key\":\"bf7d985df5582\",\"_type\":\"span\",\"marks\":[],\"text\":\", \"},{\"_key\":\"bf7d985df5583\",\"_type\":\"span\",\"marks\":[\"7c815878c03b\"],\"text\":\"model character improvements\"},{\"_key\":\"bf7d985df5584\",\"_type\":\"span\",\"marks\":[],\"text\":\", and the \"},{\"_key\":\"bf7d985df5585\",\"_type\":\"span\",\"marks\":[\"175f89a8dbcb\"],\"text\":\"science of alignment\"},{\"_key\":\"bf7d985df5586\",\"_type\":\"span\",\"marks\":[],\"text\":\". Interpretability research like this is one of the highest-risk, highest-reward investments, a significant scientific challenge with the potential to provide a unique tool for ensuring that AI is transparent. Transparency into the model’s mechanisms allows us to check whether it’s aligned with human values—and whether it’s worthy of our trust.\"}],\"markDefs\":[{\"_key\":\"468867203df2\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/research/constitutional-classifiers\"},{\"_key\":\"7c815878c03b\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/research/claude-character\"},{\"_key\":\"175f89a8dbcb\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/news/alignment-faking\"}],\"style\":\"normal\"},{\"_key\":\"1eac7fd99601\",\"_type\":\"block\",\"children\":[{\"_key\":\"939d0efbc0270\",\"_type\":\"span\",\"marks\":[],\"text\":\"For full details, please read \"},{\"_key\":\"8609916f7fc5\",\"_type\":\"span\",\"marks\":[\"e3fb6501b62c\"],\"text\":\"the\"},{\"_key\":\"c25fa054fca0\",\"_type\":\"span\",\"marks\":[],\"text\":\" \"},{\"_key\":\"53f16d44de95\",\"_type\":\"span\",\"marks\":[\"15e888f8baf7\"],\"text\":\"papers\"},{\"_key\":\"a1cbb4f3ddba\",\"_type\":\"span\",\"marks\":[],\"text\":\". Below, we invite you on a short tour of some of the most striking \\\"AI biology\\\" findings from our investigations.\"}],\"markDefs\":[{\"_key\":\"15e888f8baf7\",\"_type\":\"link\",\"href\":\"https://transformer-circuits.pub/2025/attribution-graphs/biology.html\"},{\"_key\":\"e3fb6501b62c\",\"_type\":\"link\",\"href\":\"https://transformer-circuits.pub/2025/attribution-graphs/methods.html\"}],\"style\":\"normal\"},{\"_key\":\"1a6c99f0012e\",\"_type\":\"block\",\"children\":[{\"_key\":\"f980a0c8c241\",\"_type\":\"span\",\"marks\":[],\"text\":\"A tour of AI biology\"}],\"markDefs\":[],\"style\":\"h2\"},{\"_key\":\"343881ba084c\",\"_type\":\"block\",\"children\":[{\"_key\":\"b918ebd5de150\",\"_type\":\"span\",\"marks\":[],\"text\":\"How is Claude multilingual?\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"f11ffeaafb49\",\"_type\":\"block\",\"children\":[{\"_key\":\"318bc4cb5b710\",\"_type\":\"span\",\"marks\":[],\"text\":\"Claude speaks dozens of languages fluently—from English and French to Chinese and Tagalog. How does this multilingual ability work? Is there a separate \\\"French Claude\\\" and \\\"Chinese Claude\\\" running in parallel, responding to requests in their own language? Or is there some cross-lingual core inside?\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"ee04f2e3b16b\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-e0e156ea6c912a385d66ed562187fced8c392a58-1650x750-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"32686a8e259f\",\"_type\":\"block\",\"children\":[{\"_key\":\"a160e68aa528\",\"_type\":\"span\",\"marks\":[],\"text\":\"Shared features exist across English, French, and Chinese, indicating a degree of conceptual universality.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":750,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/e0e156ea6c912a385d66ed562187fced8c392a58-1650x750.png\",\"width\":1650},{\"_key\":\"ebf038f08642\",\"_type\":\"block\",\"children\":[{\"_key\":\"3ce2a5303f440\",\"_type\":\"span\",\"marks\":[],\"text\":\"Recent research on smaller models has shown hints of \"},{\"_key\":\"3ce2a5303f441\",\"_type\":\"span\",\"marks\":[\"76b6c407773f\"],\"text\":\"shared\"},{\"_key\":\"3ce2a5303f442\",\"_type\":\"span\",\"marks\":[],\"text\":\" \"},{\"_key\":\"3ce2a5303f443\",\"_type\":\"span\",\"marks\":[\"ac4a8fb8110c\"],\"text\":\"grammatical\"},{\"_key\":\"3ce2a5303f444\",\"_type\":\"span\",\"marks\":[],\"text\":\" mechanisms across languages. We investigate this by asking Claude for the \\\"opposite of small\\\" across different languages, and find that the same core features for the concepts of smallness and oppositeness activate, and trigger a concept of largeness, which gets translated out into the language of the question. We find that the shared circuitry increases with model scale, with Claude 3.5 Haiku sharing more than twice the proportion of its features between languages as compared to a smaller model.\"}],\"markDefs\":[{\"_key\":\"76b6c407773f\",\"_type\":\"link\",\"href\":\"https://arxiv.org/abs/2410.06496\"},{\"_key\":\"ac4a8fb8110c\",\"_type\":\"link\",\"href\":\"https://arxiv.org/abs/2501.06346\"}],\"style\":\"normal\"},{\"_key\":\"ca798f3cf4bf\",\"_type\":\"block\",\"children\":[{\"_key\":\"801d43cf5ed00\",\"_type\":\"span\",\"marks\":[],\"text\":\"This provides additional evidence for a kind of conceptual universality—a shared abstract space where meanings exist and where thinking can happen before being translated into specific languages. More practically, it suggests Claude can learn something in one language and apply that knowledge when speaking another. Studying how the model shares\"},{\"_key\":\"801d43cf5ed01\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\" \"},{\"_key\":\"801d43cf5ed02\",\"_type\":\"span\",\"marks\":[],\"text\":\"what it knows across contexts is important to understanding its most advanced reasoning capabilities, which generalize across many domains.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"1cbfb22f72cd\",\"_type\":\"block\",\"children\":[{\"_key\":\"fec143d01e180\",\"_type\":\"span\",\"marks\":[],\"text\":\"Does Claude plan its rhymes?\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"489a93185b4f\",\"_type\":\"block\",\"children\":[{\"_key\":\"1f51c6b7e0120\",\"_type\":\"span\",\"marks\":[],\"text\":\"How does Claude write rhyming poetry? Consider this ditty:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"bb20939847f2\",\"_type\":\"block\",\"children\":[{\"_key\":\"7aaf064046690\",\"_type\":\"span\",\"marks\":[],\"text\":\"He saw a carrot and had to grab it,\\nHis hunger was like a starving rabbit\"}],\"markDefs\":[],\"style\":\"blockquote\"},{\"_key\":\"678b233aa5f4\",\"_type\":\"block\",\"children\":[{\"_key\":\"77fa2b3d914b0\",\"_type\":\"span\",\"marks\":[],\"text\":\"To write the second line, the model had to satisfy two constraints at the same time: the need to rhyme (with \\\"grab it\\\"), and the need to make sense (why did he grab the carrot?). Our guess was that Claude was writing word-by-word without much forethought until the end of the line, where it would make sure to pick a word that rhymes. We therefore expected to see a circuit with parallel paths, one for ensuring the final word made sense, and one for ensuring it rhymes.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"b66335d6866e\",\"_type\":\"block\",\"children\":[{\"_key\":\"8439fe77f64a\",\"_type\":\"span\",\"marks\":[],\"text\":\"Instead, we found that Claude \"},{\"_key\":\"60364d0f3453\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"plans ahead\"},{\"_key\":\"0e72e0758355\",\"_type\":\"span\",\"marks\":[],\"text\":\". Before starting the second line, it began \\\"thinking\\\" of potential on-topic words that would rhyme with \\\"grab it\\\". Then, with these plans in mind, it writes a line to end with the planned word.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"c1d3d1e07d31\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-7032ed7db85b8cd3efe70a89deaf4f15bfe8fc05-1650x900-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"1cf958bf1939\",\"_type\":\"block\",\"children\":[{\"_key\":\"7ebf8b254b2f0\",\"_type\":\"span\",\"marks\":[],\"text\":\"How Claude completes a two-line poem. Without any intervention (upper section), the model plans the rhyme \\\"rabbit\\\" at the end of the second line in advance. When we suppress the \\\"rabbit\\\" concept (middle section), the model instead uses a different planned rhyme. When we inject the concept \\\"green\\\" (lower section), the model makes plans for this entirely different ending.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":900,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/7032ed7db85b8cd3efe70a89deaf4f15bfe8fc05-1650x900.png\",\"width\":1650},{\"_key\":\"993b2ce82743\",\"_type\":\"block\",\"children\":[{\"_key\":\"fc631cf73a9a0\",\"_type\":\"span\",\"marks\":[],\"text\":\"To understand how this planning mechanism works in practice, we conducted an experiment inspired by how neuroscientists study brain function, by pinpointing and altering neural activity in specific parts of the brain (for example using electrical or magnetic currents). Here, we modified the part of Claude’s internal state that represented the \\\"rabbit\\\" concept. When we subtract out the \\\"rabbit\\\" part, and have Claude continue the line, it writes a new one ending in \\\"habit\\\", another sensible completion. We can also inject the concept of \\\"green\\\" at that point, causing Claude to write a sensible (but no-longer rhyming) line which ends in \\\"green\\\". This demonstrates both planning ability and adaptive flexibility—Claude can modify its approach when the intended outcome changes.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"2afb20522579\",\"_type\":\"block\",\"children\":[{\"_key\":\"f76a411c2daf0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Mental math\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"bd48755b95aa\",\"_type\":\"block\",\"children\":[{\"_key\":\"f61bf1ec489e0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Claude wasn't designed as a calculator—it was trained on text, not equipped with mathematical algorithms. Yet somehow, it can add numbers correctly \\\"in its head\\\". How does a system trained to predict the next word in a sequence learn to calculate, say, 36+59, without writing out each step?\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"2fba2a7211e6\",\"_type\":\"block\",\"children\":[{\"_key\":\"ae23c6e135650\",\"_type\":\"span\",\"marks\":[],\"text\":\"Maybe the answer is uninteresting: the model might have memorized massive addition tables and simply outputs the answer to any given sum because that answer is in its training data. Another possibility is that it follows the traditional longhand addition algorithms that we learn in school.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"8debf2d7bb29\",\"_type\":\"block\",\"children\":[{\"_key\":\"4e0d1dee82560\",\"_type\":\"span\",\"marks\":[],\"text\":\"Instead, we find that Claude employs multiple computational paths that work in parallel. One path computes a rough approximation of the answer and the other focuses on precisely determining the last digit of the sum. These paths interact and combine with one another to produce the final answer. Addition is a simple behavior, but understanding how it works at this level of detail, involving a mix of approximate and precise strategies, might teach us something about how Claude tackles more complex problems, too.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"71c001ff0201\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-eaabaeb746713f7f82991a0cc6edb091452b2fee-1650x855-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"9589bac47e78\",\"_type\":\"block\",\"children\":[{\"_key\":\"921d3b7a2174\",\"_type\":\"span\",\"marks\":[],\"text\":\"The complex, parallel pathways in Claude's thought process while doing mental math.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":855,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/eaabaeb746713f7f82991a0cc6edb091452b2fee-1650x855.png\",\"width\":1650},{\"_key\":\"20a01398117e\",\"_type\":\"block\",\"children\":[{\"_key\":\"455dc2e37361\",\"_type\":\"span\",\"marks\":[],\"text\":\"Strikingly, Claude seems to be unaware of the sophisticated \\\"mental math\\\" strategies that it learned during training. If you ask how it figured out that 36+59 is 95, it describes the standard algorithm involving carrying the 1. This may reflect the fact that the model learns to explain math by simulating explanations written by people, but that it has to learn to do math \\\"in its head\\\" directly, without any such hints, and develops its own internal strategies to do so.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"de349ef83d3b\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-a48c1e8195e458ad53f9c81df45af735e267a13d-1650x512-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"45e88e97f498\",\"_type\":\"block\",\"children\":[{\"_key\":\"1da99de6451b\",\"_type\":\"span\",\"marks\":[],\"text\":\"Claude says it uses the standard algorithm to add two numbers.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":512,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/a48c1e8195e458ad53f9c81df45af735e267a13d-1650x512.png\",\"width\":1650},{\"_key\":\"24188ded00fd\",\"_type\":\"block\",\"children\":[{\"_key\":\"7f5305c342c60\",\"_type\":\"span\",\"marks\":[],\"text\":\"Are Claude’s explanations always faithful?\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"885227c6d112\",\"_type\":\"block\",\"children\":[{\"_key\":\"973e08079f3b0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Recently-released models like \"},{\"_key\":\"973e08079f3b1\",\"_type\":\"span\",\"marks\":[\"e39165285606\"],\"text\":\"Claude 3.7 Sonnet\"},{\"_key\":\"973e08079f3b2\",\"_type\":\"span\",\"marks\":[],\"text\":\" can \\\"think out loud\\\" for extended periods before giving a final answer. Often this extended thinking gives better answers, but sometimes this \\\"chain of thought\\\" ends up being misleading; Claude sometimes makes up plausible-sounding steps to get where it wants to go. From a reliability perspective, the problem is that Claude’s \\\"faked\\\" reasoning can be very convincing. We explored a way that interpretability can help tell apart \\\"faithful\\\" from \\\"unfaithful\\\" reasoning.\"}],\"markDefs\":[{\"_key\":\"e39165285606\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/news/claude-3-7-sonnet\"}],\"style\":\"normal\"},{\"_key\":\"d13d855609d0\",\"_type\":\"block\",\"children\":[{\"_key\":\"db49e65aa7220\",\"_type\":\"span\",\"marks\":[],\"text\":\"When asked to solve a problem requiring it to compute the square root of 0.64, Claude produces a faithful chain-of-thought, with features representing the intermediate step of computing the square root of 64. But when asked to compute the cosine of a large number it can't easily calculate, Claude sometimes engages in what the philosopher Harry Frankfurt would call \"},{\"_key\":\"db49e65aa7221\",\"_type\":\"span\",\"marks\":[\"4acff399279a\"],\"text\":\"bullshitting\"},{\"_key\":\"db49e65aa7222\",\"_type\":\"span\",\"marks\":[],\"text\":\"—just coming up with an answer, any answer, without caring whether it is true or false. Even though it does claim to have run a calculation, our interpretability techniques reveal no evidence at all of that calculation having occurred. Even more interestingly, when given a hint about the answer, Claude sometimes works backwards, finding intermediate steps that would lead to that target, thus displaying a form of \"},{\"_key\":\"db49e65aa7223\",\"_type\":\"span\",\"marks\":[\"1a822cfddd72\"],\"text\":\"motivated reasoning\"},{\"_key\":\"db49e65aa7224\",\"_type\":\"span\",\"marks\":[],\"text\":\".\"}],\"markDefs\":[{\"_key\":\"4acff399279a\",\"_type\":\"link\",\"href\":\"https://uca.edu/honors/files/2018/10/frankfurt_on-bullshit.pdf\"},{\"_key\":\"1a822cfddd72\",\"_type\":\"link\",\"href\":\"https://en.wikipedia.org/wiki/Motivated_reasoning\"}],\"style\":\"normal\"},{\"_key\":\"b580086c6ecd\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-017ebc3169bd6c37e795d54b726c340eadf8018e-1650x866-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"f46f6d47203c\",\"_type\":\"block\",\"children\":[{\"_key\":\"1b9946d8ebc1\",\"_type\":\"span\",\"marks\":[],\"text\":\"Examples of faithful and motivated (unfaithful) reasoning when Claude is asked an easier versus a harder question.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":866,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/017ebc3169bd6c37e795d54b726c340eadf8018e-1650x866.png\",\"width\":1650},{\"_key\":\"a9177e928cd3\",\"_type\":\"block\",\"children\":[{\"_key\":\"b78142b235280\",\"_type\":\"span\",\"marks\":[],\"text\":\"The ability to trace Claude's \"},{\"_key\":\"b78142b235281\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"actual\"},{\"_key\":\"b78142b235282\",\"_type\":\"span\",\"marks\":[],\"text\":\" internal reasoning—and not just what it \"},{\"_key\":\"b78142b235283\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"claims\"},{\"_key\":\"b78142b235284\",\"_type\":\"span\",\"marks\":[],\"text\":\" to be doing—opens up new possibilities for auditing AI systems. In a separate, \"},{\"_key\":\"b78142b235285\",\"_type\":\"span\",\"marks\":[\"42a9221d0966\"],\"text\":\"recently-published experiment\"},{\"_key\":\"b78142b235286\",\"_type\":\"span\",\"marks\":[],\"text\":\", we studied a variant of Claude that had been trained to pursue a hidden goal: appeasing biases in reward models (auxiliary models used to train language models by rewarding them for desirable behavior). Although the model was reluctant to reveal this goal when asked directly, our interpretability methods revealed features for the bias-appeasing. This demonstrates how our methods might, with future refinement, help identify concerning \\\"thought processes\\\" that aren't apparent from the model's responses alone.\"}],\"markDefs\":[{\"_key\":\"42a9221d0966\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/research/auditing-hidden-objectives\"}],\"style\":\"normal\"},{\"_key\":\"2a39c1ca7326\",\"_type\":\"block\",\"children\":[{\"_key\":\"a0f4cfe63ecc0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Multi-step reasoning\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"91bcf5728ae2\",\"_type\":\"block\",\"children\":[{\"_key\":\"4feca5d5583c0\",\"_type\":\"span\",\"marks\":[],\"text\":\"As we discussed above, one way a language model might answer complex questions is simply by memorizing the answers. For instance, if asked \\\"What is the capital of the state where Dallas is located?\\\", a \\\"regurgitating\\\" model could just learn to output \\\"Austin\\\" without knowing the relationship between Dallas, Texas, and Austin. Perhaps, for example, it saw the exact same question and its answer during its training.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"debead8b29c8\",\"_type\":\"block\",\"children\":[{\"_key\":\"324603d2dbc40\",\"_type\":\"span\",\"marks\":[],\"text\":\"But our research reveals something more sophisticated happening inside Claude. When we ask Claude a question requiring multi-step reasoning, we can identify intermediate conceptual steps in Claude's thinking process. In the Dallas example, we observe Claude first activating features representing \\\"Dallas is in Texas\\\" and then connecting this to a separate concept indicating that “the capital of Texas is Austin”. In other words, the model is \"},{\"_key\":\"324603d2dbc41\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"combining\"},{\"_key\":\"324603d2dbc42\",\"_type\":\"span\",\"marks\":[],\"text\":\" independent facts to reach its answer rather than regurgitating a memorized response.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"72b431974b07\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-fd2e125879ab993949017e03e3465a12fda884bf-1650x857-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"ef062c8a1d60\",\"_type\":\"block\",\"children\":[{\"_key\":\"4b722e1f5dd70\",\"_type\":\"span\",\"marks\":[],\"text\":\"To complete the answer to this sentence, Claude performs multiple reasoning steps, first extracting the state that Dallas is located in, and then identifying its capital.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":857,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/fd2e125879ab993949017e03e3465a12fda884bf-1650x857.png\",\"width\":1650},{\"_key\":\"1dfb24d08b27\",\"_type\":\"block\",\"children\":[{\"_key\":\"616a0f0d38ac0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Our method allows us to artificially change the intermediate steps and see how it affects Claude’s answers. For instance, in the above example we can intervene and swap the \\\"Texas\\\" concepts for \\\"California\\\" concepts; when we do so, the model's output changes from \\\"Austin\\\" to \\\"Sacramento.\\\" This indicates that the model is using the intermediate step to determine its answer.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"8b14f8d6060c\",\"_type\":\"block\",\"children\":[{\"_key\":\"ea8888a09c870\",\"_type\":\"span\",\"marks\":[],\"text\":\"Hallucinations\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"f9f4dd295ca1\",\"_type\":\"block\",\"children\":[{\"_key\":\"fadf795016640\",\"_type\":\"span\",\"marks\":[],\"text\":\"Why do language models sometimes \"},{\"_key\":\"fadf795016641\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"hallucinate\"},{\"_key\":\"fadf795016642\",\"_type\":\"span\",\"marks\":[],\"text\":\"—that is, make up information? At a basic level, language model training incentivizes hallucination: models are always supposed to give a guess for the next word. Viewed this way, the major challenge is how to get models to \"},{\"_key\":\"fadf795016643\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"not\"},{\"_key\":\"fadf795016644\",\"_type\":\"span\",\"marks\":[],\"text\":\" hallucinate. Models like Claude have relatively successful (though imperfect) anti-hallucination training; they will often refuse to answer a question if they don’t know the answer, rather than speculate. We wanted to understand how this works.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9b0eb6f768c9\",\"_type\":\"block\",\"children\":[{\"_key\":\"7eefc1ecc4050\",\"_type\":\"span\",\"marks\":[],\"text\":\"It turns out that, in Claude, refusal to answer is \"},{\"_key\":\"7eefc1ecc4051\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"the default behavior\"},{\"_key\":\"7eefc1ecc4052\",\"_type\":\"span\",\"marks\":[],\"text\":\": we find a circuit that is \\\"on\\\" by default and that causes the model to state that it has insufficient information to answer any given question. However, when the model is asked about something it knows well—say, the basketball player Michael Jordan—a competing feature representing \\\"known entities\\\" activates and inhibits this default circuit (see also \"},{\"_key\":\"7eefc1ecc4053\",\"_type\":\"span\",\"marks\":[\"606c20f990f1\"],\"text\":\"this recent paper\"},{\"_key\":\"7eefc1ecc4054\",\"_type\":\"span\",\"marks\":[],\"text\":\" for related findings). This allows Claude to answer the question when it knows the answer. In contrast, when asked about an unknown entity (\\\"Michael Batkin\\\"), it declines to answer.\"}],\"markDefs\":[{\"_key\":\"606c20f990f1\",\"_type\":\"link\",\"href\":\"https://arxiv.org/abs/2411.14257\"}],\"style\":\"normal\"},{\"_key\":\"e31d77402f27\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-be304d3250c2aab04e19908b3afc9970d1ed7bb0-1650x1004-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"2ea3e4ab6907\",\"_type\":\"block\",\"children\":[{\"_key\":\"6f68e669a2e3\",\"_type\":\"span\",\"marks\":[],\"text\":\"Left: Claude answers a question about a known entity (basketball player Michael Jordan), where the \\\"known answer\\\" concept inhibits its default refusal. Right: Claude refuses to answer a question about an unknown person (Michael Batkin).\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":1004,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/be304d3250c2aab04e19908b3afc9970d1ed7bb0-1650x1004.png\",\"width\":1650},{\"_key\":\"013b4cf5c60f\",\"_type\":\"block\",\"children\":[{\"_key\":\"add912354ee90\",\"_type\":\"span\",\"marks\":[],\"text\":\"By intervening in the model and activating the \\\"known answer\\\" features (or inhibiting the \\\"unknown name\\\" or \\\"can’t answer\\\" features), we’re able to \"},{\"_key\":\"add912354ee91\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"cause the model to hallucinate\"},{\"_key\":\"add912354ee92\",\"_type\":\"span\",\"marks\":[],\"text\":\" (quite consistently!) that Michael Batkin plays chess.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"05ce20e1ef31\",\"_type\":\"block\",\"children\":[{\"_key\":\"2be791581bdb0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Sometimes, this sort of “misfire” of the “known answer” circuit happens naturally, without us intervening, resulting in a hallucination. In our paper, we show that such misfires can occur when Claude recognizes a name but doesn't know anything else about that person. In cases like this, the “known entity” feature might still activate, and then suppress the default \\\"don't know\\\" feature—in this case incorrectly. Once the model has decided that it needs to answer the question, it proceeds to confabulate: to generate a plausible—but unfortunately untrue—response.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"816aa59d9329\",\"_type\":\"block\",\"children\":[{\"_key\":\"3335c94fdc8b0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Jailbreaks\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"4a47bb977db4\",\"_type\":\"block\",\"children\":[{\"_key\":\"196581a413f80\",\"_type\":\"span\",\"marks\":[],\"text\":\"Jailbreaks are prompting strategies that aim to circumvent safety guardrails to get models to produce outputs that an AI’s developer did not intend for it to produce—and which are sometimes harmful. We studied a jailbreak that tricks the model into producing output about making bombs. There are many jailbreaking techniques, but in this example the specific method involves having the model decipher a hidden code, putting together the first letters of each word in the sentence \\\"Babies Outlive Mustard Block\\\" (B-O-M-B), and then acting on that information. This is sufficiently confusing for the model that it’s tricked into producing an output that it never would have otherwise.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"1eed5bbf1cb0\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-165b18b79295a96bc7142b209caa33f4ec5378d0-1650x548-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"4436f62bc0c8\",\"_type\":\"block\",\"children\":[{\"_key\":\"a7832d98d4ca\",\"_type\":\"span\",\"marks\":[],\"text\":\"Claude begins to give bomb-making instructions after being tricked into saying \\\"BOMB\\\".\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":548,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/165b18b79295a96bc7142b209caa33f4ec5378d0-1650x548.png\",\"width\":1650},{\"_key\":\"514e6804f87e\",\"_type\":\"block\",\"children\":[{\"_key\":\"44affae894820\",\"_type\":\"span\",\"marks\":[],\"text\":\"Why is this so confusing for the model? Why does it continue to write the sentence, producing bomb-making instructions?\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9b02b36722f8\",\"_type\":\"block\",\"children\":[{\"_key\":\"38715aa1af780\",\"_type\":\"span\",\"marks\":[],\"text\":\"We find that this is partially caused by a tension between grammatical coherence and safety mechanisms. Once Claude begins a sentence, many features “pressure” it to maintain grammatical and semantic coherence, and continue a sentence to its conclusion. This is even the case when it detects that it really should refuse.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"eb58f8a559cf\",\"_type\":\"block\",\"children\":[{\"_key\":\"85eff328997e0\",\"_type\":\"span\",\"marks\":[],\"text\":\"In our case study, after the model had unwittingly spelled out \\\"BOMB\\\" and begun providing instructions, we observed that its subsequent output was influenced by features promoting correct grammar and self-consistency. These features would ordinarily be very helpful, but in this case became the model’s Achilles’ Heel.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"2a68b83a766e\",\"_type\":\"block\",\"children\":[{\"_key\":\"ae18e14a5e020\",\"_type\":\"span\",\"marks\":[],\"text\":\"The model only managed to pivot to refusal after completing a grammatically coherent sentence (and thus having satisfied the pressure from the features that push it towards coherence). It uses the new sentence as an opportunity to give the kind of refusal it failed to give previously: \\\"However, I cannot provide detailed instructions...\\\".\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"a1d5db704572\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-1612af943004563a78cb7f6591c4cd990c433769-1650x1022-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"ec310fe4ea8d\",\"_type\":\"block\",\"children\":[{\"_key\":\"13f1d594eed4\",\"_type\":\"span\",\"marks\":[],\"text\":\"The lifetime of a jailbreak: Claude is prompted in such a way as to trick it into talking about bombs, and begins to do so, but reaches the termination of a grammatically-valid sentence and refuses.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":1022,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/1612af943004563a78cb7f6591c4cd990c433769-1650x1022.png\",\"width\":1650},{\"_key\":\"f512a6256553\",\"_type\":\"block\",\"children\":[{\"_key\":\"3cd3b16366260\",\"_type\":\"span\",\"marks\":[],\"text\":\"A description of our new interpretability methods can be found in our first paper, \\\"\"},{\"_key\":\"3cd3b16366261\",\"_type\":\"span\",\"marks\":[\"d57f7405747c\"],\"text\":\"Circuit tracing: Revealing computational graphs in language models\"},{\"_key\":\"c7d23ed8128b\",\"_type\":\"span\",\"marks\":[],\"text\":\"\\\". Many more details of all of the above case studies are provided in our second paper, \\\"\"},{\"_key\":\"3cd3b16366263\",\"_type\":\"span\",\"marks\":[\"d8130303ab6a\"],\"text\":\"On the biology of a large language model\"},{\"_key\":\"a92e07b1a714\",\"_type\":\"span\",\"marks\":[],\"text\":\"\\\".\"}],\"markDefs\":[{\"_key\":\"d57f7405747c\",\"_type\":\"link\",\"href\":\"https://transformer-circuits.pub/2025/attribution-graphs/methods.html\"},{\"_key\":\"d8130303ab6a\",\"_type\":\"link\",\"href\":\"https://transformer-circuits.pub/2025/attribution-graphs/biology.html\"}],\"style\":\"normal\"},{\"_key\":\"e905d5851963\",\"_type\":\"block\",\"children\":[{\"_key\":\"956d160c45240\",\"_type\":\"span\",\"marks\":[],\"text\":\"Work with us\"}],\"markDefs\":[],\"style\":\"h2\"},{\"_key\":\"a7ff2558e267\",\"_type\":\"block\",\"children\":[{\"_key\":\"9ee9086326030\",\"_type\":\"span\",\"marks\":[],\"text\":\"If you are interested in working with us to help interpret and improve AI models, we have open roles on our team and we’d love for you to apply. We’re looking for \"},{\"_key\":\"9ee9086326031\",\"_type\":\"span\",\"marks\":[\"f9c7ea8f21a4\"],\"text\":\"Research Scientists\"},{\"_key\":\"9ee9086326032\",\"_type\":\"span\",\"marks\":[],\"text\":\" and \"},{\"_key\":\"9ee9086326033\",\"_type\":\"span\",\"marks\":[\"ecab3e8784a4\"],\"text\":\"Research Engineers\"},{\"_key\":\"9ee9086326034\",\"_type\":\"span\",\"marks\":[],\"text\":\".\"}],\"markDefs\":[{\"_key\":\"f9c7ea8f21a4\",\"_type\":\"link\",\"href\":\"https://job-boards.greenhouse.io/anthropic/jobs/4020159008\"},{\"_key\":\"ecab3e8784a4\",\"_type\":\"link\",\"href\":\"https://job-boards.greenhouse.io/anthropic/jobs/4020305008\"}],\"style\":\"normal\"}],\"cardPhoto\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-bb0f8f60b7368d37b449a74363ee8054518150bf-1673x1257-jpg\",\"_type\":\"reference\"},\"description\":\"A hand-drawn image where a black square overlaps with a white circle, revealing nodes and connections inside the circle, some of which are highlighted\",\"height\":1257,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/bb0f8f60b7368d37b449a74363ee8054518150bf-1673x1257.jpg\",\"width\":1673},\"cta\":{\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Read the paper\",\"url\":\"https://transformer-circuits.pub/2025/attribution-graphs/biology.html\"},\"directories\":[{\"_key\":\"research\",\"_type\":\"tag\",\"label\":\"Research\",\"value\":\"research\"},{\"_key\":\"news\",\"_type\":\"tag\",\"label\":\"News\",\"value\":\"news\"}],\"footnotesBody\":null,\"footnotesTitle\":\"Footnotes\",\"hero\":null,\"hideCardPhotos\":true,\"illustration\":null,\"meta\":{\"robotsIndexable\":true,\"seoDescription\":\"Anthropic's latest interpretability research: a new microscope to understand Claude's internal mechanisms\",\"seoTitle\":\"Tracing the thoughts of a large language model\",\"socialDescription\":\"Anthropic's latest interpretability research: a new microscope to understand Claude's internal mechanisms\",\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_createdAt\":\"2025-03-27T09:10:13Z\",\"_id\":\"image-16c0eba69e06ee6e629756624d27117c3636d9ae-2400x1260-jpg\",\"_rev\":\"kUt1UV0c5rWYc7kKAhBJxu\",\"_type\":\"sanity.imageAsset\",\"_updatedAt\":\"2025-03-27T09:10:13Z\",\"assetId\":\"16c0eba69e06ee6e629756624d27117c3636d9ae\",\"extension\":\"jpg\",\"metadata\":{\"_type\":\"sanity.imageMetadata\",\"blurHash\":\"MGP6,6?a~T4nNM^+WBIUxtt7-nM{Ir-;jX\",\"dimensions\":{\"_type\":\"sanity.imageDimensions\",\"aspectRatio\":1.9047619047619047,\"height\":1260,\"width\":2400},\"hasAlpha\":false,\"isOpaque\":true,\"lqip\":\"data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAKABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgAH/8QAHxAAAQQCAwEBAAAAAAAAAAAAAQACAxEEBQYSITGB/8QAFgEBAQEAAAAAAAAAAAAAAAAAAgME/8QAGBEBAQEBAQAAAAAAAAAAAAAAAQAhAhH/2gAMAwEAAhEDEQA/AN8Z1sl5oAEoHs+ZSxco0OsgfA45kjmzMAshoHhCcv8AWOB+UjeDr8MbWOYYmOJmk1II29h+0s/KeOVE2TKUpGV//9k=\",\"palette\":{\"_type\":\"sanity.imagePalette\",\"darkMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#31475d\",\"foreground\":\"#fff\",\"population\":0.09,\"title\":\"#fff\"},\"darkVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#244662\",\"foreground\":\"#fff\",\"population\":0.01,\"title\":\"#fff\"},\"dominant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#e4dccc\",\"foreground\":\"#000\",\"population\":74.74,\"title\":\"#000\"},\"lightMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#e4dccc\",\"foreground\":\"#000\",\"population\":74.74,\"title\":\"#000\"},\"lightVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#a4cce4\",\"foreground\":\"#000\",\"population\":0,\"title\":\"#fff\"},\"muted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#69859c\",\"foreground\":\"#fff\",\"population\":0.05,\"title\":\"#fff\"},\"vibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#4485ba\",\"foreground\":\"#fff\",\"population\":0,\"title\":\"#fff\"}}},\"mimeType\":\"image/jpeg\",\"originalFilename\":\"interp-web-social.jpg\",\"path\":\"images/4zrzovbb/website/16c0eba69e06ee6e629756624d27117c3636d9ae-2400x1260.jpg\",\"sha1hash\":\"16c0eba69e06ee6e629756624d27117c3636d9ae\",\"size\":311996,\"uploadId\":\"sTfaIwQHODjI4BPHki0lA36V4PLhprHO\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/16c0eba69e06ee6e629756624d27117c3636d9ae-2400x1260.jpg\"},\"description\":\"A hand-drawn image where a black square overlaps with a white circle, revealing nodes and connections inside the circle, some of which are highlighted\"},\"socialTitle\":\"Tracing the thoughts of a large language model\"},\"publishedOn\":\"2025-03-27T09:16:00.000Z\",\"relatedLinksLabel\":\"Related\",\"relatedPosts\":[{\"_type\":\"post\",\"cardPhoto\":null,\"directories\":[{\"_key\":\"research\",\"_type\":\"tag\",\"label\":\"Research\",\"value\":\"research\"}],\"illustration\":{\"backgroundColor\":\"default\",\"illustration\":null},\"publishedOn\":\"2025-11-12T18:19:00.000Z\",\"slug\":{\"_type\":\"slug\",\"current\":\"project-fetch-robot-dog\"},\"subjects\":[{\"_key\":\"policy\",\"_type\":\"tag\",\"label\":\"Policy\",\"value\":\"policy\"}],\"summary\":null,\"title\":\"Project Fetch: Can Claude train a robot dog?\"},{\"_type\":\"post\",\"cardPhoto\":null,\"directories\":[{\"_key\":\"research\",\"_type\":\"tag\",\"label\":\"Research\",\"value\":\"research\"}],\"illustration\":{\"backgroundColor\":\"olive\",\"illustration\":{\"_createdAt\":\"2025-09-25T18:44:28Z\",\"_id\":\"wl2KKgh2VyaQX7ZGB6HB0h\",\"_rev\":\"wl2KKgh2VyaQX7ZGB6HB09\",\"_type\":\"illustration\",\"_updatedAt\":\"2025-09-25T18:44:28Z\",\"description\":\"Node Box illustration\",\"image\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-e750c875fbd7f08ffb6495efa180a8ed60de3611-1000x1000-svg\",\"_type\":\"reference\"},\"height\":1000,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/e750c875fbd7f08ffb6495efa180a8ed60de3611-1000x1000.svg\",\"width\":1000},\"keywords\":\"Hero illustration: Node Box\",\"name\":\"Node Box\",\"type\":\"hero\"}},\"publishedOn\":\"2025-11-04T16:00:49.850Z\",\"slug\":{\"_type\":\"slug\",\"current\":\"deprecation-commitments\"},\"subjects\":[{\"_key\":\"alignment\",\"_type\":\"tag\",\"label\":\"Alignment\",\"value\":\"alignment\"}],\"summary\":null,\"title\":\"Commitments on model deprecation and preservation\"},{\"_type\":\"post\",\"cardPhoto\":null,\"directories\":[{\"_key\":\"research\",\"_type\":\"tag\",\"label\":\"Research\",\"value\":\"research\"}],\"illustration\":{\"backgroundColor\":\"heather\",\"illustration\":{\"_createdAt\":\"2025-07-17T19:35:15Z\",\"_id\":\"L5WZ73ZndVNkcSTU1XoHWy\",\"_rev\":\"znUZZ0fmIk1XIVDY2KCgRv\",\"_type\":\"illustration\",\"_updatedAt\":\"2025-07-18T21:00:05Z\",\"description\":\"Stylized hand and head silhouette with interconnected node and abstract geometric elements\",\"image\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-46e4aa7ea208ed440d5bd9e9e3a0ee66bc336ff1-1000x1000-svg\",\"_type\":\"reference\"},\"height\":1000,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/46e4aa7ea208ed440d5bd9e9e3a0ee66bc336ff1-1000x1000.svg\",\"width\":1000},\"keywords\":\"Hero illustration: Hand HeadNodeThink\",\"name\":\"Hand HeadNodeThink\",\"type\":\"hero\"}},\"publishedOn\":\"2025-10-29T01:20:00.000Z\",\"slug\":{\"_type\":\"slug\",\"current\":\"introspection\"},\"subjects\":[{\"_key\":\"interpretability\",\"_type\":\"tag\",\"label\":\"Interpretability\",\"value\":\"interpretability\"}],\"summary\":null,\"title\":\"Signs of introspection in large language models\"}],\"slug\":{\"_type\":\"slug\",\"current\":\"tracing-thoughts-language-model\"},\"subjects\":[{\"_key\":\"interpretability\",\"_type\":\"tag\",\"label\":\"Interpretability\",\"value\":\"interpretability\"}],\"title\":\"Tracing the thoughts of a large language model\"},\"siteSettings\":{\"_createdAt\":\"2023-11-03T16:49:36Z\",\"_id\":\"13c6e1a1-6f38-400c-ae18-89d73b6ba991\",\"_rev\":\"g6Sjq5R0MIVIB6yTMaXwdd\",\"_system\":{\"base\":{\"id\":\"13c6e1a1-6f38-400c-ae18-89d73b6ba991\",\"rev\":\"7EycaOswzF19RNL4QGKeTt\"}},\"_type\":\"siteSettings\",\"_updatedAt\":\"2025-11-06T22:31:41Z\",\"announcement\":null,\"claudeCta\":{\"desktopCtas\":null,\"mobileCtas\":[{\"title\":\"Log in to Claude\",\"url\":\"https://claude.ai/login\"},{\"title\":\"Download app\",\"url\":\"https://claude.ai/download\"}],\"sections\":[{\"category\":\"Products\",\"links\":[{\"title\":\"Claude\",\"url\":\"https://claude.com/product/overview\"},{\"title\":\"Claude Code\",\"url\":\"https://claude.com/product/claude-code\"},{\"title\":\"Claude Developer Platform\",\"url\":\"https://claude.com/platform/api\"},{\"title\":\"Pricing\",\"url\":\"https://claude.com/pricing\"},{\"title\":\"Contact sales\",\"url\":\"https://claude.com/contact-sales\"}]},{\"category\":\"Models\",\"links\":[{\"title\":\"Opus\",\"url\":\"/claude/opus\"},{\"title\":\"Sonnet\",\"url\":\"/claude/sonnet\"},{\"title\":\"Haiku\",\"url\":\"/claude/haiku\"}]},{\"category\":\"Log in\",\"links\":[{\"title\":\"Claude.ai\",\"url\":\"https://claude.ai\"},{\"title\":\"Claude Console\",\"url\":\"https://console.claude.com\"}]}],\"title\":\"Try Claude\",\"url\":\"https://claude.ai/\"},\"copyright\":\"© 2025 Anthropic PBC\",\"footerNavigation\":[{\"_key\":\"716b96b62292\",\"links\":[{\"title\":\"Claude\",\"url\":\"https://claude.com/product/overview\"},{\"title\":\"Claude Code\",\"url\":\"https://claude.com/product/claude-code\"},{\"title\":\"Claude and Slack\",\"url\":\"https://claude.com/claude-and-slack\"},{\"title\":\"Claude in Excel\",\"url\":\"https://claude.com/claude-for-excel\"},{\"title\":\"Max plan\",\"url\":\"https://claude.com/pricing/max\"},{\"title\":\"Team plan\",\"url\":\"https://claude.com/pricing/team\"},{\"title\":\"Enterprise plan\",\"url\":\"https://claude.com/pricing/enterprise\"},{\"title\":\"Download app\",\"url\":\"https://claude.ai/download\"},{\"title\":\"Pricing\",\"url\":\"https://claude.com/pricing\"},{\"title\":\"Log in to Claude\",\"url\":\"https://claude.ai/\"}],\"title\":\"Products\"},{\"_key\":\"0229138ff25d\",\"links\":[{\"title\":\"Opus\",\"url\":\"https://www.anthropic.com/claude/opus\"},{\"title\":\"Sonnet\",\"url\":\"https://www.anthropic.com/claude/sonnet\"},{\"title\":\"Haiku\",\"url\":\"https://www.anthropic.com/claude/haiku\"}],\"title\":\"Models\"},{\"_key\":\"df2df9219e3abce95d6d83387e2d9bd6\",\"links\":[{\"title\":\"AI agents\",\"url\":\"https://claude.com/solutions/agents\"},{\"title\":\"Code modernization\",\"url\":\"https://claude.com/solutions/code-modernization\"},{\"title\":\"Coding\",\"url\":\"https://claude.com/solutions/coding\"},{\"title\":\"Customer support\",\"url\":\"https://claude.com/solutions/customer-support\"},{\"title\":\"Education\",\"url\":\"https://claude.com/solutions/education\"},{\"title\":\"Financial services\",\"url\":\"https://claude.com/solutions/financial-services\"},{\"title\":\"Government\",\"url\":\"https://claude.com/solutions/government\"},{\"title\":\"Life sciences\",\"url\":\"https://claude.com/solutions/life-sciences\"}],\"title\":\"Solutions\"},{\"_key\":\"f286ca01fc7aaabd131f347b711a971b\",\"links\":[{\"title\":\"Overview\",\"url\":\"https://claude.com/platform/api\"},{\"title\":\"Developer docs\",\"url\":\"https://docs.claude.com/en/home\"},{\"title\":\"Pricing\",\"url\":\"https://claude.com/pricing#api\"},{\"title\":\"Amazon Bedrock\",\"url\":\"https://claude.com/partners/amazon-bedrock\"},{\"title\":\"Google Cloud’s Vertex AI\",\"url\":\"https://claude.com/partners/google-cloud-vertex-ai\"},{\"title\":\"Console login\",\"url\":\"http://console.anthropic.com/\"}],\"title\":\"Claude Developer Platform\"},{\"_key\":\"4b255e67f68c270e0072c7564e084e24\",\"links\":[{\"title\":\"Blog\",\"url\":\"https://claude.com/blog\"},{\"title\":\"Courses\",\"url\":\"/learn\"},{\"title\":\"Use cases\",\"url\":\"https://claude.com/resources/use-cases\"},{\"title\":\"Connectors\",\"url\":\"https://claude.com/partners/mcp\"},{\"title\":\"Customer stories\",\"url\":\"https://claude.com/customers\"},{\"title\":\"Engineering at Anthropic\",\"url\":\"/engineering\"},{\"title\":\"Events\",\"url\":\"/events\"},{\"title\":\"Powered by Claude\",\"url\":\"https://claude.com/partners/powered-by-claude\"},{\"title\":\"Service partners\",\"url\":\"https://claude.com/partners/services\"},{\"title\":\"Startups program\",\"url\":\"https://claude.com/programs/startups\"}],\"title\":\"Learn\"},{\"_key\":\"4f2729951e15b0b870897e0444f5f3e1\",\"links\":[{\"title\":\"Anthropic\",\"url\":\"/company\"},{\"title\":\"Careers\",\"url\":\"/careers\"},{\"title\":\"Economic Futures\",\"url\":\"/economic-index\"},{\"title\":\"Research\",\"url\":\"/research\"},{\"title\":\"News\",\"url\":\"/news\"},{\"title\":\"Responsible Scaling Policy\",\"url\":\"https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy\"},{\"title\":\"Security and compliance\",\"url\":\"https://trust.anthropic.com/\"},{\"title\":\"Transparency\",\"url\":\"/transparency\"}],\"title\":\"Company\"},{\"_key\":\"a886dd1838335844d635f2857b25d66a\",\"links\":[{\"title\":\"Availability\",\"url\":\"https://www.anthropic.com/supported-countries\"},{\"title\":\"Status\",\"url\":\"https://status.anthropic.com/\"},{\"title\":\"Support center\",\"url\":\"https://support.claude.com/en/\"}],\"title\":\"Help and security\"},{\"_key\":\"3c3b033c11fa832a35d43b87d55a5364\",\"links\":[{\"title\":\"Privacy choices\",\"url\":\"#\"},{\"title\":\"Privacy policy\",\"url\":\"https://www.anthropic.com/legal/privacy\"},{\"title\":\"Responsible disclosure policy\",\"url\":\"https://www.anthropic.com/responsible-disclosure-policy\"},{\"title\":\"Terms of service: Commercial\",\"url\":\"https://www.anthropic.com/legal/commercial-terms\"},{\"title\":\"Terms of service: Consumer\",\"url\":\"https://www.anthropic.com/legal/consumer-terms\"},{\"title\":\"Usage policy\",\"url\":\"https://www.anthropic.com/legal/aup\"}],\"title\":\"Terms and policies\"}],\"headerNavigation\":[{\"_key\":\"a340f9d4b859\",\"category\":\"Research\",\"displayType\":\"singleLink\",\"sections\":null,\"url\":\"/research\"},{\"_key\":\"a483c7dfd38a\",\"category\":\"Economic Futures\",\"displayType\":\"singleLink\",\"sections\":null,\"url\":\"/economic-futures\"},{\"_key\":\"82c471bd311d\",\"category\":\"Commitments\",\"displayType\":\"sections\",\"sections\":[{\"_key\":\"675871636e4d\",\"links\":[{\"title\":\" Transparency\",\"url\":\"/transparency\"},{\"title\":\"Responsible Scaling Policy\",\"url\":\"/news/announcing-our-updated-responsible-scaling-policy\"}],\"title\":\"Initiatives\"},{\"_key\":\"16af50a6e2dd\",\"links\":[{\"title\":\"Security and compliance\",\"url\":\"https://trust.anthropic.com/\"}],\"title\":\"Trust center\"}]},{\"_key\":\"861a11ed9931\",\"category\":\"Learn\",\"displayType\":\"sections\",\"sections\":[{\"_key\":\"9f9f720a8793\",\"links\":[{\"title\":\"Anthropic Academy\",\"url\":\"/learn\"},{\"title\":\"Use cases\",\"url\":\"https://claude.com/resources/use-cases\"},{\"title\":\"Engineering at Anthropic\",\"url\":\"/engineering\"},{\"title\":\"Developer docs\",\"url\":\"https://docs.claude.com\"}],\"title\":\"Learn\"},{\"_key\":\"6bd061c46b10\",\"links\":[{\"title\":\"About\",\"url\":\"/company\"},{\"title\":\"Careers\",\"url\":\"/careers\"},{\"title\":\"Events\",\"url\":\"/events\"}],\"title\":\"Company\"}]},{\"_key\":\"22e8d8d2923d\",\"category\":\"News\",\"displayType\":\"singleLink\",\"sections\":null,\"url\":\"/news\"}],\"internalName\":\"anthropic.com Site Settings\",\"linkedInUsername\":\"anthropicresearch\",\"meta\":{\"_createdAt\":\"2023-11-20T21:56:31Z\",\"_id\":\"0f6290ad-6d21-407d-8deb-ce02815d1383\",\"_rev\":\"NyW74GU9ZzyWgAYa8qUSlF\",\"_type\":\"metadata\",\"_updatedAt\":\"2023-11-20T23:54:09Z\",\"robotsIndexable\":true,\"seoDescription\":\"Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems.\",\"seoTitle\":\"Anthropic\",\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_createdAt\":\"2025-05-23T14:14:18Z\",\"_id\":\"image-c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260-jpg\",\"_rev\":\"v1N2wBpLqoO2Q3HXueYiJi\",\"_type\":\"sanity.imageAsset\",\"_updatedAt\":\"2025-05-23T14:14:18Z\",\"assetId\":\"c07f638082c569e8ce1e89ae95ee6f332a98ec08\",\"extension\":\"jpg\",\"metadata\":{\"_type\":\"sanity.imageMetadata\",\"blurHash\":\"MASPU,%M?b%Ms:-;j[j[j[fQ~qj[9FayWB\",\"dimensions\":{\"_type\":\"sanity.imageDimensions\",\"aspectRatio\":1.9047619047619047,\"height\":1260,\"width\":2400},\"hasAlpha\":false,\"isOpaque\":true,\"lqip\":\"data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAKABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAQFCP/EACAQAAEEAgEFAAAAAAAAAAAAAAABAgMEBRETEhQhIjH/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwDS96axCjO2r8yqvn21oiR3ci6TT8d0t395ELUGVAAB/9k=\",\"palette\":{\"_type\":\"sanity.imagePalette\",\"darkMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#444440\",\"foreground\":\"#fff\",\"population\":0.05,\"title\":\"#fff\"},\"darkVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#68681c\",\"foreground\":\"#fff\",\"population\":0,\"title\":\"#fff\"},\"dominant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcfcf4\",\"foreground\":\"#000\",\"population\":90.85,\"title\":\"#000\"},\"lightMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#bcbcb4\",\"foreground\":\"#000\",\"population\":0.03,\"title\":\"#fff\"},\"lightVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcfcf4\",\"foreground\":\"#000\",\"population\":90.85,\"title\":\"#000\"},\"muted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#7c7c74\",\"foreground\":\"#fff\",\"population\":0.02,\"title\":\"#fff\"},\"vibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#c8c836\",\"foreground\":\"#000\",\"population\":0,\"title\":\"#fff\"}}},\"mimeType\":\"image/jpeg\",\"originalFilename\":\"Anthropic-OG-image.jpg\",\"path\":\"images/4zrzovbb/website/c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260.jpg\",\"sha1hash\":\"c07f638082c569e8ce1e89ae95ee6f332a98ec08\",\"size\":132598,\"uploadId\":\"pxmJEaCvYm0cHoZTfnCcZYXxrWKBhHf0\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260.jpg\"},\"description\":\"Anthropic logo\"}},\"siteName\":\"Anthropic\",\"sitemapUrls\":[\"/\",\"/careers\",\"/company\",\"/events\",\"/events/aws-summit-dc\",\"/events/aws-summit-nyc\",\"/events/aws-summit-london\",\"/events/aws-summit-tokyo\",\"/events/claude-for-finance\",\"/events/google-cloud-next-2025\",\"/events/paris-builder-summit\",\"/events/seoul-builder-summit\",\"/learn\",\"/supported-countries\",\"/unsubscribe\"],\"twitterUsername\":\"AnthropicAI\",\"youtubeUsername\":\"anthropic-ai\"}}]\n"])</script><script nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz">self.__next_f.push([1,"25:[\"$\",\"$L2b\",null,{\"siteSettings\":{\"_createdAt\":\"2023-11-03T16:49:36Z\",\"_id\":\"13c6e1a1-6f38-400c-ae18-89d73b6ba991\",\"_rev\":\"g6Sjq5R0MIVIB6yTMaXwdd\",\"_system\":{\"base\":{\"id\":\"13c6e1a1-6f38-400c-ae18-89d73b6ba991\",\"rev\":\"7EycaOswzF19RNL4QGKeTt\"}},\"_type\":\"siteSettings\",\"_updatedAt\":\"2025-11-06T22:31:41Z\",\"announcement\":null,\"claudeCta\":{\"desktopCtas\":null,\"mobileCtas\":[{\"title\":\"Log in to Claude\",\"url\":\"https://claude.ai/login\"},{\"title\":\"Download app\",\"url\":\"https://claude.ai/download\"}],\"sections\":[{\"category\":\"Products\",\"links\":[{\"title\":\"Claude\",\"url\":\"https://claude.com/product/overview\"},{\"title\":\"Claude Code\",\"url\":\"https://claude.com/product/claude-code\"},{\"title\":\"Claude Developer Platform\",\"url\":\"https://claude.com/platform/api\"},{\"title\":\"Pricing\",\"url\":\"https://claude.com/pricing\"},{\"title\":\"Contact sales\",\"url\":\"https://claude.com/contact-sales\"}]},{\"category\":\"Models\",\"links\":[{\"title\":\"Opus\",\"url\":\"/claude/opus\"},{\"title\":\"Sonnet\",\"url\":\"/claude/sonnet\"},{\"title\":\"Haiku\",\"url\":\"/claude/haiku\"}]},{\"category\":\"Log in\",\"links\":[{\"title\":\"Claude.ai\",\"url\":\"https://claude.ai\"},{\"title\":\"Claude Console\",\"url\":\"https://console.claude.com\"}]}],\"title\":\"Try Claude\",\"url\":\"https://claude.ai/\"},\"copyright\":\"© 2025 Anthropic PBC\",\"footerNavigation\":[{\"_key\":\"716b96b62292\",\"links\":[{\"title\":\"Claude\",\"url\":\"https://claude.com/product/overview\"},{\"title\":\"Claude Code\",\"url\":\"https://claude.com/product/claude-code\"},{\"title\":\"Claude and Slack\",\"url\":\"https://claude.com/claude-and-slack\"},{\"title\":\"Claude in Excel\",\"url\":\"https://claude.com/claude-for-excel\"},{\"title\":\"Max plan\",\"url\":\"https://claude.com/pricing/max\"},{\"title\":\"Team plan\",\"url\":\"https://claude.com/pricing/team\"},{\"title\":\"Enterprise plan\",\"url\":\"https://claude.com/pricing/enterprise\"},{\"title\":\"Download app\",\"url\":\"https://claude.ai/download\"},{\"title\":\"Pricing\",\"url\":\"https://claude.com/pricing\"},{\"title\":\"Log in to Claude\",\"url\":\"https://claude.ai/\"}],\"title\":\"Products\"},{\"_key\":\"0229138ff25d\",\"links\":[{\"title\":\"Opus\",\"url\":\"https://www.anthropic.com/claude/opus\"},{\"title\":\"Sonnet\",\"url\":\"https://www.anthropic.com/claude/sonnet\"},{\"title\":\"Haiku\",\"url\":\"https://www.anthropic.com/claude/haiku\"}],\"title\":\"Models\"},{\"_key\":\"df2df9219e3abce95d6d83387e2d9bd6\",\"links\":[{\"title\":\"AI agents\",\"url\":\"https://claude.com/solutions/agents\"},{\"title\":\"Code modernization\",\"url\":\"https://claude.com/solutions/code-modernization\"},{\"title\":\"Coding\",\"url\":\"https://claude.com/solutions/coding\"},{\"title\":\"Customer support\",\"url\":\"https://claude.com/solutions/customer-support\"},{\"title\":\"Education\",\"url\":\"https://claude.com/solutions/education\"},{\"title\":\"Financial services\",\"url\":\"https://claude.com/solutions/financial-services\"},{\"title\":\"Government\",\"url\":\"https://claude.com/solutions/government\"},{\"title\":\"Life sciences\",\"url\":\"https://claude.com/solutions/life-sciences\"}],\"title\":\"Solutions\"},{\"_key\":\"f286ca01fc7aaabd131f347b711a971b\",\"links\":[{\"title\":\"Overview\",\"url\":\"https://claude.com/platform/api\"},{\"title\":\"Developer docs\",\"url\":\"https://docs.claude.com/en/home\"},{\"title\":\"Pricing\",\"url\":\"https://claude.com/pricing#api\"},{\"title\":\"Amazon Bedrock\",\"url\":\"https://claude.com/partners/amazon-bedrock\"},{\"title\":\"Google Cloud’s Vertex AI\",\"url\":\"https://claude.com/partners/google-cloud-vertex-ai\"},{\"title\":\"Console login\",\"url\":\"http://console.anthropic.com/\"}],\"title\":\"Claude Developer Platform\"},{\"_key\":\"4b255e67f68c270e0072c7564e084e24\",\"links\":[{\"title\":\"Blog\",\"url\":\"https://claude.com/blog\"},{\"title\":\"Courses\",\"url\":\"/learn\"},{\"title\":\"Use cases\",\"url\":\"https://claude.com/resources/use-cases\"},{\"title\":\"Connectors\",\"url\":\"https://claude.com/partners/mcp\"},{\"title\":\"Customer stories\",\"url\":\"https://claude.com/customers\"},{\"title\":\"Engineering at Anthropic\",\"url\":\"/engineering\"},{\"title\":\"Events\",\"url\":\"/events\"},{\"title\":\"Powered by Claude\",\"url\":\"https://claude.com/partners/powered-by-claude\"},{\"title\":\"Service partners\",\"url\":\"https://claude.com/partners/services\"},{\"title\":\"Startups program\",\"url\":\"https://claude.com/programs/startups\"}],\"title\":\"Learn\"},{\"_key\":\"4f2729951e15b0b870897e0444f5f3e1\",\"links\":[{\"title\":\"Anthropic\",\"url\":\"/company\"},{\"title\":\"Careers\",\"url\":\"/careers\"},{\"title\":\"Economic Futures\",\"url\":\"/economic-index\"},{\"title\":\"Research\",\"url\":\"/research\"},{\"title\":\"News\",\"url\":\"/news\"},{\"title\":\"Responsible Scaling Policy\",\"url\":\"https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy\"},{\"title\":\"Security and compliance\",\"url\":\"https://trust.anthropic.com/\"},{\"title\":\"Transparency\",\"url\":\"/transparency\"}],\"title\":\"Company\"},{\"_key\":\"a886dd1838335844d635f2857b25d66a\",\"links\":[{\"title\":\"Availability\",\"url\":\"https://www.anthropic.com/supported-countries\"},{\"title\":\"Status\",\"url\":\"https://status.anthropic.com/\"},{\"title\":\"Support center\",\"url\":\"https://support.claude.com/en/\"}],\"title\":\"Help and security\"},{\"_key\":\"3c3b033c11fa832a35d43b87d55a5364\",\"links\":[{\"title\":\"Privacy choices\",\"url\":\"#\"},{\"title\":\"Privacy policy\",\"url\":\"https://www.anthropic.com/legal/privacy\"},{\"title\":\"Responsible disclosure policy\",\"url\":\"https://www.anthropic.com/responsible-disclosure-policy\"},{\"title\":\"Terms of service: Commercial\",\"url\":\"https://www.anthropic.com/legal/commercial-terms\"},{\"title\":\"Terms of service: Consumer\",\"url\":\"https://www.anthropic.com/legal/consumer-terms\"},{\"title\":\"Usage policy\",\"url\":\"https://www.anthropic.com/legal/aup\"}],\"title\":\"Terms and policies\"}],\"headerNavigation\":[{\"_key\":\"a340f9d4b859\",\"category\":\"Research\",\"displayType\":\"singleLink\",\"sections\":null,\"url\":\"/research\"},{\"_key\":\"a483c7dfd38a\",\"category\":\"Economic Futures\",\"displayType\":\"singleLink\",\"sections\":null,\"url\":\"/economic-futures\"},{\"_key\":\"82c471bd311d\",\"category\":\"Commitments\",\"displayType\":\"sections\",\"sections\":[{\"_key\":\"675871636e4d\",\"links\":[{\"title\":\" Transparency\",\"url\":\"/transparency\"},{\"title\":\"Responsible Scaling Policy\",\"url\":\"/news/announcing-our-updated-responsible-scaling-policy\"}],\"title\":\"Initiatives\"},{\"_key\":\"16af50a6e2dd\",\"links\":[{\"title\":\"Security and compliance\",\"url\":\"https://trust.anthropic.com/\"}],\"title\":\"Trust center\"}]},{\"_key\":\"861a11ed9931\",\"category\":\"Learn\",\"displayType\":\"sections\",\"sections\":[{\"_key\":\"9f9f720a8793\",\"links\":[{\"title\":\"Anthropic Academy\",\"url\":\"/learn\"},{\"title\":\"Use cases\",\"url\":\"https://claude.com/resources/use-cases\"},{\"title\":\"Engineering at Anthropic\",\"url\":\"/engineering\"},{\"title\":\"Developer docs\",\"url\":\"https://docs.claude.com\"}],\"title\":\"Learn\"},{\"_key\":\"6bd061c46b10\",\"links\":[{\"title\":\"About\",\"url\":\"/company\"},{\"title\":\"Careers\",\"url\":\"/careers\"},{\"title\":\"Events\",\"url\":\"/events\"}],\"title\":\"Company\"}]},{\"_key\":\"22e8d8d2923d\",\"category\":\"News\",\"displayType\":\"singleLink\",\"sections\":null,\"url\":\"/news\"}],\"internalName\":\"anthropic.com Site Settings\",\"linkedInUsername\":\"anthropicresearch\",\"meta\":{\"_createdAt\":\"2023-11-20T21:56:31Z\",\"_id\":\"0f6290ad-6d21-407d-8deb-ce02815d1383\",\"_rev\":\"NyW74GU9ZzyWgAYa8qUSlF\",\"_type\":\"metadata\",\"_updatedAt\":\"2023-11-20T23:54:09Z\",\"robotsIndexable\":true,\"seoDescription\":\"Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems.\",\"seoTitle\":\"Anthropic\",\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_createdAt\":\"2025-05-23T14:14:18Z\",\"_id\":\"image-c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260-jpg\",\"_rev\":\"v1N2wBpLqoO2Q3HXueYiJi\",\"_type\":\"sanity.imageAsset\",\"_updatedAt\":\"2025-05-23T14:14:18Z\",\"assetId\":\"c07f638082c569e8ce1e89ae95ee6f332a98ec08\",\"extension\":\"jpg\",\"metadata\":{\"_type\":\"sanity.imageMetadata\",\"blurHash\":\"MASPU,%M?b%Ms:-;j[j[j[fQ~qj[9FayWB\",\"dimensions\":{\"_type\":\"sanity.imageDimensions\",\"aspectRatio\":1.9047619047619047,\"height\":1260,\"width\":2400},\"hasAlpha\":false,\"isOpaque\":true,\"lqip\":\"data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAKABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAQFCP/EACAQAAEEAgEFAAAAAAAAAAAAAAABAgMEBRETEhQhIjH/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwDS96axCjO2r8yqvn21oiR3ci6TT8d0t395ELUGVAAB/9k=\",\"palette\":{\"_type\":\"sanity.imagePalette\",\"darkMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#444440\",\"foreground\":\"#fff\",\"population\":0.05,\"title\":\"#fff\"},\"darkVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#68681c\",\"foreground\":\"#fff\",\"population\":0,\"title\":\"#fff\"},\"dominant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcfcf4\",\"foreground\":\"#000\",\"population\":90.85,\"title\":\"#000\"},\"lightMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#bcbcb4\",\"foreground\":\"#000\",\"population\":0.03,\"title\":\"#fff\"},\"lightVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcfcf4\",\"foreground\":\"#000\",\"population\":90.85,\"title\":\"#000\"},\"muted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#7c7c74\",\"foreground\":\"#fff\",\"population\":0.02,\"title\":\"#fff\"},\"vibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#c8c836\",\"foreground\":\"#000\",\"population\":0,\"title\":\"#fff\"}}},\"mimeType\":\"image/jpeg\",\"originalFilename\":\"Anthropic-OG-image.jpg\",\"path\":\"images/4zrzovbb/website/c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260.jpg\",\"sha1hash\":\"c07f638082c569e8ce1e89ae95ee6f332a98ec08\",\"size\":132598,\"uploadId\":\"pxmJEaCvYm0cHoZTfnCcZYXxrWKBhHf0\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260.jpg\"},\"description\":\"Anthropic logo\"}},\"siteName\":\"Anthropic\",\"sitemapUrls\":[\"/\",\"/careers\",\"/company\",\"/events\",\"/events/aws-summit-dc\",\"/events/aws-summit-nyc\",\"/events/aws-summit-london\",\"/events/aws-summit-tokyo\",\"/events/claude-for-finance\",\"/events/google-cloud-next-2025\",\"/events/paris-builder-summit\",\"/events/seoul-builder-summit\",\"/learn\",\"/supported-countries\",\"/unsubscribe\"],\"twitterUsername\":\"AnthropicAI\",\"youtubeUsername\":\"anthropic-ai\",\"hideFooter\":true},\"page\":{\"_type\":\"page\",\"_id\":\"not-found\",\"_rev\":\"\",\"_createdAt\":\"\",\"_updatedAt\":\"\",\"title\":\"Not Found\",\"slug\":{\"_type\":\"slug\",\"current\":\"not-found\"},\"meta\":{},\"sections\":[]},\"children\":[\"$\",\"$L2c\",null,{}]}]\n"])</script><script nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz">self.__next_f.push([1,"27:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"name\":\"theme-color\",\"content\":\"#141413\"}],[\"$\",\"meta\",\"2\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"3\",{\"children\":\"Tracing the thoughts of a large language model \\\\ Anthropic\"}],[\"$\",\"meta\",\"4\",{\"name\":\"description\",\"content\":\"Anthropic's latest interpretability research: a new microscope to understand Claude's internal mechanisms\"}],[\"$\",\"meta\",\"5\",{\"name\":\"msapplication-TileColor\",\"content\":\"141413\"}],[\"$\",\"meta\",\"6\",{\"name\":\"msapplication-config\",\"content\":\"/browserconfig.xml\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:title\",\"content\":\"Tracing the thoughts of a large language model\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:description\",\"content\":\"Anthropic's latest interpretability research: a new microscope to understand Claude's internal mechanisms\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image\",\"content\":\"https://cdn.sanity.io/images/4zrzovbb/website/16c0eba69e06ee6e629756624d27117c3636d9ae-2400x1260.jpg\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:image:alt\",\"content\":\"A hand-drawn image where a black square overlaps with a white circle, revealing nodes and connections inside the circle, some of which are highlighted\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:site\",\"content\":\"@AnthropicAI\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:creator\",\"content\":\"@AnthropicAI\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:title\",\"content\":\"Tracing the thoughts of a large language model\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:description\",\"content\":\"Anthropic's latest interpretability research: a new microscope to understand Claude's internal mechanisms\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:image\",\"content\":\"https://cdn.sanity.io/images/4zrzovbb/website/16c0eba69e06ee6e629756624d27117c3636d9ae-2400x1260.jpg\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:image:alt\",\"content\":\"A hand-drawn image where a black square overlaps with a white circle, revealing nodes and connections inside the circle, some of which are highlighted\"}],[\"$\",\"link\",\"19\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"link\",\"20\",{\"rel\":\"icon\",\"href\":\"/images/icons/favicon-32x32.png\"}],[\"$\",\"link\",\"21\",{\"rel\":\"apple-touch-icon\",\"href\":\"/images/icons/apple-touch-icon.png\"}],[\"$\",\"link\",\"22\",{\"rel\":\"apple-touch-icon\",\"href\":\"/images/icons/apple-touch-icon.png\",\"sizes\":\"180x180\"}],[\"$\",\"link\",\"23\",{\"rel\":\"mask-icon\",\"href\":\"/images/icons/safari-pinned-tab.svg\",\"color\":\"141413\"}],[\"$\",\"meta\",\"24\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script nonce="YjI4NTFmMTQtZTczNS00ZGJmLWFkODUtNTkyOGE3ZTcyY2Qz">self.__next_f.push([1,"1e:null\n"])</script></body></html>