Research Publications | Lambda Lambda raises over $1.5B from TWG Global, USIT to build Superintelligence Cloud infrastructure. Learn more Log in Get started Create account Talk to our team Building a vision for the AI developer Unlocking compute for AI developers to innovate and create. Apply for a grant Pushing the frontier of AI/ML research Neural software: from vision to reality Join Lambda's co-founder and CEO Stephen Balaban as he unveils Neural Software: an entirely new way of thinking about software that can collaborate with humans, evolve over time and adapt like never before. Watch the video Our latest projects 01 Latent Thought Models with Variational Bayes Inference-Time Computation We propose Latent Thought Models (LTMs), a novel family of language models that incorporate explicit latent thought vectors to guide autoregressive generation. Read more 02 Product of Experts with LLMs Boosting performance on ARC is a matter of perspective. Read the ICML'25 Paper by "The ARChitects" (winning team of ARC prize 2024). Read more 03 NORA: Neural Orchestrator for Robotics Autonomy NORA adopts the Qwen-2.5-VL-3B multimodal model as the backbone, leveraging its superior visual-semantic understanding to enhance visual reasoning and action grounding. Read more 04 TANGOFLUX: Super Fast and Faithful Text to Audio Generation We introduce TANGOFLUX, an efficient Text-to-Audio (TTA) generative model with 515M parameters, capable of generating up to 30 seconds of 44.1kHz audio in just 3.7 seconds on a single A40 GPU. Read more LLM performance benchmarks leaderboard Providing a clear, data-driven comparison of today's leading large language models. We present standardized benchmark results for top contenders like Meta's Llama 4 series, Alibaba's Qwen3, and the latest from DeepSeek, focusing on critical performance metrics that measure everything from coding ability to general knowledge. See benchmarks Text2Video leaderboard Ranking text-to-video models by human preference. Side-by-side, no cherry-picking. Start testing ML Times Your go-to source for the latest in the field, curated by AI. Sift through the excess. Make every word count. Get started Distributed Training Guide Our zero-to-hero guide for scaling up distributed training in PyTorch. Get started Boost research with best practices and system insights 01 Diffusion From Scratch A guide for diffusion models implemented in a single PyTorch script. Learn more 02 Text2Video Pretraining Lessons learned from training a text-to-video model with hundreds of GPUs. Learn more 03 GPU Benchmarks Throughput GPU benchmarks for training deep neural networks. Learn more 04 MLCommon Benchmark Time-to-solution benchmark for training foundation models on clusters. Learn more Recognized by scholars and industry peers BMVC 2022 clip2latent Text driven sampling of a pre-trained stylegan using denoising diffusion and clip ICCV 2021 Personalized Video Summarization With Multiple Pairwise Ranking Networks ACM Trans. Graph. 2019 Adversarial Monte Carlo denoising With conditioned auxiliary feature modulation ICCV 2019 HoloGAN Unsupervised Learning of 3D Representations from Natural Images neurIPS 2018 RenderNet A Deep Convolutional Network for Differentiable Rendering from 3D Shapes ECCV 2016 MGANs Precomputed real-time texture synthesis with markovian generative adversarial networks CVPR 2016 CNNMRF Combining markov random fields and convolutional neural networks for image synthesis SPIE 2015 Deep Learning and Face Recognition The State of the Art Join us in shaping the future of AI We're committed to supporting groundbreaking research by offering qualifying researchers up to $5,000 in cloud credits to develop and showcase their work using Lambda's On-Demand Cloud platform, with select research to be featured on our website. Apply now